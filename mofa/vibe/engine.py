"""Core Vibe engine for agent generation"""

import os
import re
from pathlib import Path
from typing import Optional
from datetime import datetime

from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
from rich.table import Table
from rich.prompt import Prompt, Confirm

from .models import (
    VibeConfig,
    TestSuite,
    TestCase,
    AgentCode,
    GenerationRound,
    GenerationResult,
    TestResult
)
from .llm_client import LLMClient
from .scaffolder import ProjectScaffolder
from .debug_runner import DebugRunner


class VibeEngine:
    """Main orchestrator for agent generation"""

    def __init__(self, config: Optional[VibeConfig] = None):
        self.config = config or VibeConfig()
        self.console = Console()
        self.llm = LLMClient(
            model=self.config.llm_model,
            api_key=self.config.llm_api_key,
            temperature=self.config.temperature
        )
        self.scaffolder = ProjectScaffolder(output_dir=self.config.output_dir)
        self.debug_runner = DebugRunner()

        # State
        self.requirement = ""
        self.agent_name = ""
        self.test_suite: Optional[TestSuite] = None
        self.rounds: list[GenerationRound] = []
        self.project_path = ""

    def run_interactive(self) -> GenerationResult:
        """Run in interactive mode"""
        self._show_header()

        # Step 1: Get requirement from user
        self._ask_requirement()

        # Step 2: Generate and confirm test cases
        self._generate_and_confirm_tests()

        # Step 3: Auto-generate and optimize
        result = self._auto_optimize_loop()

        # Step 4: Show final summary
        self._show_final_summary(result)

        return result

    def _show_header(self):
        """Display welcome header"""
        self.console.print(Panel(
            "[bold cyan]ğŸ¤– MoFA Vibe - AI Agent Generator[/bold cyan]\n"
            "Automatically generate agents from requirements",
            border_style="cyan"
        ))
        self.console.print()

    def _ask_requirement(self):
        """Ask user for agent requirement"""
        self.console.print("ğŸ“ [bold]è¯·æè¿°ä½ æƒ³è¦çš„AgentåŠŸèƒ½:[/bold]")
        self.requirement = Prompt.ask(">", console=self.console)

        # Generate agent name from requirement
        self.agent_name = self._generate_agent_name(self.requirement)

        # Ask if user wants to customize name
        self.console.print(f"\nğŸ’¡ å»ºè®®çš„Agentåç§°: [cyan]{self.agent_name}[/cyan]")
        if not Confirm.ask("ä½¿ç”¨è¿™ä¸ªåç§°?", default=True, console=self.console):
            self.agent_name = Prompt.ask("è¯·è¾“å…¥Agentåç§°", console=self.console)

    def _generate_agent_name(self, requirement: str) -> str:
        """Generate agent name from requirement"""
        # Simple heuristic: take first few words and slugify
        words = requirement.lower().split()[:3]
        name = '-'.join(words)
        # Remove special characters
        name = re.sub(r'[^a-z0-9-]', '', name)
        return name or "custom-agent"

    def _generate_and_confirm_tests(self):
        """Generate test cases and get user confirmation"""
        self.console.print("\nâœ¨ [bold]æ­£åœ¨åˆ†æå¹¶ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...[/bold]")

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=self.console,
            transient=True
        ) as progress:
            task = progress.add_task("ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹", total=None)

            # Generate test cases using LLM
            test_yaml = self.llm.generate_test_cases(self.requirement)

            # Clean up any markdown code blocks
            test_yaml = self._clean_yaml_response(test_yaml)

            progress.update(task, completed=True)

        # Display generated tests
        self.console.print("\n" + "â”" * 60)
        self.console.print("ğŸ“‹ [bold]ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹:[/bold]")
        self.console.print("â”" * 60)
        self.console.print()

        syntax = Syntax(test_yaml, "yaml", theme="monokai", line_numbers=False)
        self.console.print(syntax)
        self.console.print()

        # Ask for confirmation
        while True:
            response = Prompt.ask(
                "è¿™äº›æµ‹è¯•ç”¨ä¾‹å¯ä»¥å—?",
                choices=["y", "n", "edit"],
                default="y",
                console=self.console
            )

            if response == "y":
                self.test_suite = TestSuite.from_yaml(test_yaml)
                break
            elif response == "edit":
                self.console.print("\nè¯·ç¼–è¾‘æµ‹è¯•ç”¨ä¾‹ï¼ˆå®Œæˆåè¾“å…¥ç©ºè¡Œï¼‰:")
                lines = []
                while True:
                    line = input()
                    if line == "" and lines:
                        break
                    lines.append(line)
                test_yaml = "\n".join(lines)
                self.test_suite = TestSuite.from_yaml(test_yaml)
                break
            else:  # n
                self.console.print("âš ï¸  è¯·æ‰‹åŠ¨æè¿°ä½ æƒ³è¦çš„æµ‹è¯•ç”¨ä¾‹:")
                manual_tests = Prompt.ask(">", console=self.console)
                self.requirement += f"\n\næµ‹è¯•è¦æ±‚: {manual_tests}"
                # Regenerate
                return self._generate_and_confirm_tests()

    def _clean_yaml_response(self, yaml_str: str) -> str:
        """Remove markdown code blocks from LLM response"""
        # Remove ```yaml and ``` markers
        yaml_str = re.sub(r'```yaml\n', '', yaml_str)
        yaml_str = re.sub(r'```\n?', '', yaml_str)
        return yaml_str.strip()

    def _auto_optimize_loop(self) -> GenerationResult:
        """Automatic generation and optimization loop"""
        self.console.print("\n" + "â”" * 60)
        self.console.print("ğŸš€ [bold]å¼€å§‹è‡ªåŠ¨ç”Ÿæˆå’Œä¼˜åŒ–[/bold]")
        self.console.print("â”" * 60)
        self.console.print("[dim]æç¤º: æŒ‰ Ctrl+C æš‚åœï¼Œå¯é€‰æ‹©ä¿å­˜å½“å‰ç‰ˆæœ¬[/dim]\n")

        current_code = None
        test_result = None

        try:
            for round_num in range(1, self.config.max_optimization_rounds + 1):
                self.console.print(f"\n[bold cyan]Round {round_num}[/bold cyan] {'â”' * 40}")

                # Generate or regenerate code
                if round_num == 1:
                    current_code = self._generate_initial_code()
                else:
                    current_code = self._regenerate_code(current_code, test_result)

                # Create/update project
                self.project_path = self._create_project(current_code)

                # Run tests
                test_result = self._run_tests()

                # Save round
                round_data = GenerationRound(
                    round_number=round_num,
                    code=current_code,
                    test_result=test_result,
                    optimization_note="" if round_num == 1 else "è‡ªåŠ¨ä¼˜åŒ–"
                )
                self.rounds.append(round_data)

                # Display result
                self._display_round_result(test_result)

                # Check if all tests passed
                if test_result.all_passed:
                    self.console.print(f"\n[bold green]âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¼˜åŒ–å®Œæˆ[/bold green]")
                    break

        except KeyboardInterrupt:
            self.console.print("\n\nâ¸ï¸  [yellow]ç”¨æˆ·æš‚åœ[/yellow]")
            return self._handle_pause()

        # Create final result
        return GenerationResult(
            success=test_result.all_passed if test_result else False,
            agent_name=self.agent_name,
            agent_path=self.project_path,
            rounds=self.rounds,
            test_suite=self.test_suite,
            final_code=current_code,
            final_test_result=test_result
        )

    def _generate_initial_code(self) -> AgentCode:
        """Generate initial agent code"""
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=self.console,
            transient=True
        ) as progress:
            task = progress.add_task("ğŸ“ ç”Ÿæˆä»£ç ...", total=None)

            code_str = self.llm.generate_code(
                requirement=self.requirement,
                test_cases_yaml=self.test_suite.to_yaml(),
                agent_name=self.agent_name
            )

            # Clean up code (remove markdown)
            code_str = self._clean_code_response(code_str)

            progress.update(task, description="ğŸ“ ç”Ÿæˆä»£ç ... âœ“")

        return AgentCode(main_py=code_str, agent_name=self.agent_name)

    def _regenerate_code(self, previous_code: AgentCode, test_result: TestResult) -> AgentCode:
        """Regenerate code based on test failures"""
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=self.console,
            transient=True
        ) as progress:
            task1 = progress.add_task("ğŸ’¡ åˆ†æé”™è¯¯...", total=None)

            failure_info = self.debug_runner.format_failures(test_result)

            progress.update(task1, description="ğŸ’¡ åˆ†æé”™è¯¯... âœ“")
            task2 = progress.add_task("ğŸ”§ ä¼˜åŒ–ä»£ç ...", total=None)

            code_str = self.llm.regenerate_code(
                original_code=previous_code.main_py,
                test_failures=failure_info,
                requirement=self.requirement
            )

            code_str = self._clean_code_response(code_str)

            progress.update(task2, description="ğŸ”§ ä¼˜åŒ–ä»£ç ... âœ“")

        return AgentCode(main_py=code_str, agent_name=self.agent_name)

    def _clean_code_response(self, code_str: str) -> str:
        """Remove markdown code blocks from LLM response"""
        # Remove ```python and ``` markers
        code_str = re.sub(r'```python\n', '', code_str)
        code_str = re.sub(r'```\n?', '', code_str)
        return code_str.strip()

    def _create_project(self, code: AgentCode) -> str:
        """Create or update project files"""
        project_path = self.scaffolder.create_project(
            agent_name=self.agent_name,
            code=code.main_py,
            test_yaml=self.test_suite.to_yaml(),
            dependencies=code.dependencies
        )
        return project_path

    def _run_tests(self) -> TestResult:
        """Run mofa debug tests"""
        test_yaml_path = os.path.join(
            self.project_path,
            "tests",
            f"test_{self.agent_name.replace('-', '_')}.yml"
        )

        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=self.console,
            transient=True
        ) as progress:
            task = progress.add_task("ğŸ” è¿è¡Œæµ‹è¯•...", total=None)

            result = self.debug_runner.run_tests(self.project_path, test_yaml_path)

            progress.update(task, description="ğŸ” è¿è¡Œæµ‹è¯•... âœ“")

        return result

    def _display_round_result(self, result: TestResult):
        """Display test results for a round"""
        status_emoji = "âœ“" if result.all_passed else "âœ—"
        status_color = "green" if result.all_passed else "red"

        self.console.print(
            f"  ğŸ“Š Pass: {result.passed}/{result.total} "
            f"({result.pass_rate:.1f}%) [{status_color}]{status_emoji}[/{status_color}]"
        )

        # Show failed tests
        if not result.all_passed:
            for test in result.get_failed_tests():
                self.console.print(f"  [red]âŒ {test.name}[/red]")

    def _handle_pause(self) -> GenerationResult:
        """Handle user pause - allow selecting version"""
        if not self.rounds:
            self.console.print("âŒ è¿˜æ²¡æœ‰ç”Ÿæˆä»»ä½•ç‰ˆæœ¬")
            return None

        # Show version history
        self.console.print("\n[bold]ç‰ˆæœ¬å†å²:[/bold]")
        table = Table()
        table.add_column("ç‰ˆæœ¬", style="cyan")
        table.add_column("é€šè¿‡ç‡", style="white")
        table.add_column("çŠ¶æ€", style="white")

        for round_data in self.rounds:
            status = "âœ“" if round_data.test_result.all_passed else "âœ—"
            table.add_row(
                f"Round {round_data.round_number}",
                f"{round_data.test_result.pass_rate:.1f}%",
                status
            )

        self.console.print(table)

        # Ask which version to use
        version_num = Prompt.ask(
            "\né€‰æ‹©è¦ä½¿ç”¨çš„ç‰ˆæœ¬ (è¾“å…¥round number)",
            default=str(len(self.rounds)),
            console=self.console
        )

        try:
            selected_round = self.rounds[int(version_num) - 1]

            # Update project with selected version
            self.project_path = self._create_project(selected_round.code)

            return GenerationResult(
                success=selected_round.test_result.all_passed,
                agent_name=self.agent_name,
                agent_path=self.project_path,
                rounds=self.rounds,
                test_suite=self.test_suite,
                final_code=selected_round.code,
                final_test_result=selected_round.test_result
            )

        except (ValueError, IndexError):
            self.console.print("âŒ æ— æ•ˆçš„ç‰ˆæœ¬å·")
            return self._handle_pause()

    def _show_final_summary(self, result: GenerationResult):
        """Display final summary"""
        if not result:
            return

        self.console.print("\n" + "â”" * 60)
        if result.success:
            self.console.print("[bold green]ğŸ‰ ç”ŸæˆæˆåŠŸï¼[/bold green]")
        else:
            self.console.print("[bold yellow]âš ï¸  ç”Ÿæˆå®Œæˆï¼ˆéƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼‰[/bold yellow]")
        self.console.print("â”" * 60)
        self.console.print()

        # Summary info
        info_table = Table.grid(padding=(0, 2))
        info_table.add_column(style="cyan bold")
        info_table.add_column(style="white")

        info_table.add_row("âœ… Agent:", result.agent_name)
        info_table.add_row("ğŸ“‚ ä½ç½®:", result.agent_path)
        info_table.add_row(
            "ğŸ“Š é€šè¿‡ç‡:",
            f"{result.final_test_result.pass_rate:.1f}% "
            f"({result.final_test_result.passed}/{result.final_test_result.total})"
        )
        info_table.add_row("ğŸ”„ ä¼˜åŒ–è½®æ¬¡:", str(result.total_rounds))

        self.console.print(info_table)
        self.console.print()

        # Version history
        if len(result.rounds) > 1:
            self.console.print("[bold]ç‰ˆæœ¬å†å²:[/bold]")
            for round_data in result.rounds:
                status = "â­" if round_data == result.rounds[-1] else "  "
                emoji = "âœ“" if round_data.test_result.all_passed else "âœ—"
                self.console.print(
                    f"  {status} [{round_data.round_number}] Round {round_data.round_number} - "
                    f"{round_data.test_result.pass_rate:.1f}% passed {emoji}"
                )
            self.console.print()

        self.console.print(f"[dim]ä½¿ç”¨ç‰ˆæœ¬: Round {result.rounds[-1].round_number}[/dim]\n")
