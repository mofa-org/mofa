//! æ ‡å‡† LLM Agent å®ç°
//! Standard LLM Agent implementation
//!
//! æ¡†æ¶æä¾›çš„å¼€ç®±å³ç”¨çš„ LLM Agentï¼Œç”¨æˆ·åªéœ€é…ç½® provider å³å¯ä½¿ç”¨
//! Out-of-the-box LLM Agent provided by the framework; users only need to configure the provider.
//!
//! # ç¤ºä¾‹
//! # Example
//!
//! ```rust,ignore
//! use mofa_sdk::kernel::AgentInput;
//! use mofa_sdk::runtime::run_agents;
//! use mofa_sdk::llm::LLMAgentBuilder;
//!
//! #[tokio::main]
//! async fn main() -> GlobalResult<()> {
//!     let agent = LLMAgentBuilder::from_env()?
//!         .with_id("my-llm-agent")
//!         .with_system_prompt("You are a helpful assistant.")
//!         .build();
//!
//!     let outputs = run_agents(agent, vec![AgentInput::text("Hello")]).await?;
//!     println!("{}", outputs[0].to_text());
//!     Ok(())
//! }
//! ```

use mofa_kernel::agent::types::error::{GlobalError, GlobalResult};
use super::client::{ChatSession, LLMClient};
use super::provider::{ChatStream, LLMProvider};
use super::tool_executor::ToolExecutor;
use super::types::{ChatMessage, LLMError, LLMResult, Tool};
use crate::llm::{
    AnthropicConfig, AnthropicProvider, GeminiConfig, GeminiProvider, OllamaConfig, OllamaProvider,
};
use crate::prompt;
use futures::{Stream, StreamExt};
use mofa_kernel::agent::AgentMetadata;
use mofa_kernel::agent::AgentState;
use mofa_kernel::plugin::{AgentPlugin, PluginType};
use mofa_plugins::tts::TTSPlugin;
use std::collections::HashMap;
use std::io::Write;
use std::pin::Pin;
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use std::time::Duration;
use tokio::sync::{Mutex, RwLock};

/// Type alias for TTS audio stream - boxed to avoid exposing kokoro-tts types
pub type TtsAudioStream = Pin<Box<dyn Stream<Item = (Vec<f32>, Duration)> + Send>>;

/// Cancellation token for cooperative cancellation
struct CancellationToken {
    cancel: Arc<AtomicBool>,
}

impl CancellationToken {
    fn new() -> Self {
        Self {
            cancel: Arc::new(AtomicBool::new(false)),
        }
    }

    fn is_cancelled(&self) -> bool {
        self.cancel.load(Ordering::Relaxed)
    }

    fn cancel(&self) {
        self.cancel.store(true, Ordering::Relaxed);
    }

    fn clone_token(&self) -> CancellationToken {
        CancellationToken {
            cancel: Arc::clone(&self.cancel),
        }
    }
}

/// æµå¼æ–‡æœ¬å“åº”ç±»å‹
/// Streaming text response type
///
/// æ¯æ¬¡ yield ä¸€ä¸ªæ–‡æœ¬ç‰‡æ®µï¼ˆdelta contentï¼‰
/// Yields a text fragment (delta content) each time
pub type TextStream = Pin<Box<dyn Stream<Item = LLMResult<String>> + Send>>;

/// TTS æµå¥æŸ„ï¼šæŒæœ‰ sink å’Œæ¶ˆè´¹è€…ä»»åŠ¡
/// TTS stream handle: holds sink and consumer task
///
/// ç”¨äºå®æ—¶æµå¼ TTSï¼Œå…è®¸ incremental æäº¤æ–‡æœ¬
/// Used for real-time streaming TTS, allowing incremental text submission
#[cfg(feature = "kokoro")]
struct TTSStreamHandle {
    sink: mofa_plugins::tts::kokoro_wrapper::SynthSink<String>,
    _stream_handle: tokio::task::JoinHandle<()>,
}

/// Active TTS session with cancellation support
struct TTSSession {
    cancellation_token: CancellationToken,
    is_active: Arc<AtomicBool>,
}

impl TTSSession {
    fn new(token: CancellationToken) -> Self {
        let is_active = Arc::new(AtomicBool::new(true));
        TTSSession {
            cancellation_token: token,
            is_active,
        }
    }

    fn cancel(&self) {
        self.cancellation_token.cancel();
        self.is_active.store(false, Ordering::Relaxed);
    }

    fn is_active(&self) -> bool {
        self.is_active.load(Ordering::Relaxed)
    }
}

/// å¥å­ç¼“å†²åŒºï¼šæŒ‰æ ‡ç‚¹ç¬¦å·æ–­å¥ï¼ˆå†…éƒ¨å®ç°ï¼‰
/// Sentence buffer: splits sentences by punctuation (internal implementation)
struct SentenceBuffer {
    buffer: String,
}

impl SentenceBuffer {
    fn new() -> Self {
        Self {
            buffer: String::new(),
        }
    }

    /// æ¨å…¥æ–‡æœ¬å—ï¼Œè¿”å›å®Œæ•´å¥å­ï¼ˆå¦‚æœæœ‰ï¼‰
    /// Pushes text block, returns full sentence (if any)
    fn push(&mut self, text: &str) -> Option<String> {
        for ch in text.chars() {
            self.buffer.push(ch);
            // å¥æœ«æ ‡ç‚¹ï¼šã€‚ï¼ï¼Ÿ!?
            // Sentence-ending punctuation: ã€‚ï¼ï¼Ÿ!?
            if matches!(ch, 'ã€‚' | 'ï¼' | 'ï¼Ÿ' | '!' | '?') {
                let sentence = self.buffer.trim().to_string();
                if !sentence.is_empty() {
                    self.buffer.clear();
                    return Some(sentence);
                }
            }
        }
        None
    }

    /// åˆ·æ–°å‰©ä½™å†…å®¹
    /// Flushes remaining content
    fn flush(&mut self) -> Option<String> {
        if self.buffer.trim().is_empty() {
            None
        } else {
            let remaining = self.buffer.trim().to_string();
            self.buffer.clear();
            Some(remaining)
        }
    }
}

/// æµå¼å“åº”äº‹ä»¶
/// Streaming response events
#[derive(Debug, Clone)]
pub enum StreamEvent {
    /// æ–‡æœ¬ç‰‡æ®µ
    /// Text fragment
    Text(String),
    /// å·¥å…·è°ƒç”¨å¼€å§‹
    /// Tool call start
    ToolCallStart { id: String, name: String },
    /// å·¥å…·è°ƒç”¨å‚æ•°ç‰‡æ®µ
    /// Tool call arguments fragment
    ToolCallDelta { id: String, arguments_delta: String },
    /// å®ŒæˆåŸå› 
    /// Completion reason
    Done(Option<String>),
}

/// LLM Agent é…ç½®
/// LLM Agent configuration
#[derive(Clone)]
pub struct LLMAgentConfig {
    /// Agent ID
    pub agent_id: String,
    /// Agent åç§°
    /// Agent name
    pub name: String,
    /// ç³»ç»Ÿæç¤ºè¯
    /// System prompt
    pub system_prompt: Option<String>,
    /// é»˜è®¤æ¸©åº¦
    /// Default temperature
    pub temperature: Option<f32>,
    /// é»˜è®¤æœ€å¤§ token æ•°
    /// Default maximum tokens
    pub max_tokens: Option<u32>,
    /// è‡ªå®šä¹‰é…ç½®
    /// Custom configuration
    pub custom_config: HashMap<String, String>,
    /// ç”¨æˆ· IDï¼Œç”¨äºæ•°æ®åº“æŒä¹…åŒ–å’Œå¤šç”¨æˆ·åœºæ™¯
    /// User ID, for database persistence and multi-user scenarios
    pub user_id: Option<String>,
    /// ç§Ÿæˆ· IDï¼Œç”¨äºå¤šç§Ÿæˆ·æ”¯æŒ
    /// Tenant ID, for multi-tenant support
    pub tenant_id: Option<String>,
    /// ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼Œç”¨äºæ»‘åŠ¨çª—å£æ¶ˆæ¯ managementï¼ˆå•ä½ï¼šè½®æ•°/roundsï¼‰
    /// Context window size, for sliding window message management (unit: rounds)
    ///
    /// æ³¨æ„ï¼šå•ä½æ˜¯**è½®æ•°**ï¼ˆroundsï¼‰ï¼Œä¸æ˜¯ token æ•°é‡
    /// Note: The unit is **rounds**, not token counts
    /// æ¯è½®å¯¹è¯ â‰ˆ 1 ä¸ªç”¨æˆ·æ¶ˆæ¯ + 1 ä¸ªåŠ©æ‰‹å“åº”
    /// Each round â‰ˆ 1 user message + 1 assistant response
    pub context_window_size: Option<usize>,
}

impl Default for LLMAgentConfig {
    fn default() -> Self {
        Self {
            agent_id: "llm-agent".to_string(),
            name: "LLM Agent".to_string(),
            system_prompt: None,
            temperature: Some(0.7),
            max_tokens: Some(4096),
            custom_config: HashMap::new(),
            user_id: None,
            tenant_id: None,
            context_window_size: None,
        }
    }
}

/// æ ‡å‡† LLM Agent
/// Standard LLM Agent
///
/// æ¡†æ¶æä¾›çš„å¼€ç®±å³ç”¨çš„ LLM Agent å®ç°
/// Out-of-the-box LLM Agent implementation provided by the framework
///
/// # å¤šä¼šè¯æ”¯æŒ
/// # Multi-session support
///
/// LLMAgent æ”¯æŒå¤šä¼šè¯ç®¡ç†ï¼Œæ¯ä¸ªä¼šè¯æœ‰å”¯ä¸€çš„ session_idï¼š
/// LLMAgent supports multi-session management, each session having a unique session_id:
///
/// ```rust,ignore
/// // åˆ›å»ºæ–°ä¼šè¯
/// // Create new session
/// let session_id = agent.create_session().await;
///
/// // ä½¿ç”¨æŒ‡å®šä¼šè¯å¯¹è¯
/// // Chat with specified session
/// agent.chat_with_session(&session_id, "Hello").await?;
///
/// // åˆ‡æ¢é»˜è®¤ä¼šè¯
/// // Switch default session
/// agent.switch_session(&session_id).await?;
///
/// // è·å–æ‰€æœ‰ä¼šè¯ID
/// // Get all session IDs
/// let sessions = agent.list_sessions().await;
/// ```
///
/// # TTS æ”¯æŒ
/// # TTS support
///
/// LLMAgent æ”¯æŒé€šè¿‡ç»Ÿä¸€çš„æ’ä»¶ç³»ç»Ÿé…ç½® TTSï¼š
/// LLMAgent supports configuring TTS via a unified plugin system:
///
/// ```rust,ignore
/// // åˆ›å»º TTS æ’ä»¶ï¼ˆå¼•æ“ + å¯é€‰éŸ³è‰²ï¼‰
/// // Create TTS plugin (engine + optional voice)
/// let tts_plugin = TTSPlugin::with_engine("tts", kokoro_engine, Some("zf_090"));
///
/// // é€šè¿‡æ’ä»¶ç³»ç»Ÿæ·»åŠ 
/// // Add via plugin system
/// let agent = LLMAgentBuilder::new()
///     .with_id("my-agent")
///     .with_provider(Arc::new(openai_from_env()?))
///     .with_plugin(tts_plugin)
///     .build();
///
/// // ç›´æ¥ä½¿ç”¨ TTS
/// // Use TTS directly
/// agent.tts_speak("Hello world").await?;
///
/// // é«˜çº§ç”¨æ³•ï¼šè‡ªå®šä¹‰é…ç½®
/// // Advanced usage: custom configuration
/// let tts_plugin = TTSPlugin::with_engine("tts", kokoro_engine, Some("zf_090"))
///     .with_config(TTSPluginConfig {
///         streaming_chunk_size: 8192,
///         ..Default::default()
///     });
/// ```
pub struct LLMAgent {
    config: LLMAgentConfig,
    /// æ™ºèƒ½ä½“å…ƒæ•°æ®
    /// Agent metadata
    metadata: AgentMetadata,
    client: LLMClient,
    /// å¤šä¼šè¯å­˜å‚¨ (session_id -> ChatSession)
    /// Multi-session storage (session_id -> ChatSession)
    sessions: Arc<RwLock<HashMap<String, Arc<RwLock<ChatSession>>>>>,
    /// å½“å‰æ´»åŠ¨ä¼šè¯ID
    /// Current active session ID
    active_session_id: Arc<RwLock<String>>,
    tools: Vec<Tool>,
    tool_executor: Option<Arc<dyn ToolExecutor>>,
    event_handler: Option<Box<dyn LLMAgentEventHandler>>,
    /// æ’ä»¶åˆ—è¡¨
    /// Plugin list
    plugins: Vec<Box<dyn AgentPlugin>>,
    /// å½“å‰æ™ºèƒ½ä½“çŠ¶æ€
    /// Current agent state
    state: AgentState,
    /// ä¿å­˜ provider ç”¨äºåˆ›å»ºæ–°ä¼šè¯
    /// Save provider for creating new sessions
    provider: Arc<dyn LLMProvider>,
    /// Prompt æ¨¡æ¿æ’ä»¶
    /// Prompt template plugin
    prompt_plugin: Option<Box<dyn prompt::PromptTemplatePlugin>>,
    /// TTS æ’ä»¶ï¼ˆé€šè¿‡ builder é…ç½®ï¼‰
    /// TTS plugin (configured via builder)
    tts_plugin: Option<Arc<Mutex<TTSPlugin>>>,
    /// ç¼“å­˜çš„ Kokoro TTS å¼•æ“ï¼ˆåªéœ€åˆå§‹åŒ–ä¸€æ¬¡ï¼Œåç»­å¯å¤ç”¨ï¼‰
    /// Cached Kokoro TTS engine (initialize once, reuse later)
    #[cfg(feature = "kokoro")]
    cached_kokoro_engine: Arc<Mutex<Option<Arc<mofa_plugins::tts::kokoro_wrapper::KokoroTTS>>>>,
    /// Active TTS session for cancellation
    active_tts_session: Arc<Mutex<Option<TTSSession>>>,
    /// æŒä¹…åŒ–å­˜å‚¨ï¼ˆå¯é€‰ï¼Œç”¨äºä»æ•°æ®åº“åŠ è½½å†å²ä¼šè¯ï¼‰
    /// Persistent storage (optional, for loading session history from database)
    message_store: Option<Arc<dyn crate::persistence::MessageStore + Send + Sync>>,
    session_store: Option<Arc<dyn crate::persistence::SessionStore + Send + Sync>>,
    /// ç”¨æˆ· IDï¼ˆç”¨äºä»æ•°æ®åº“åŠ è½½ä¼šè¯ï¼‰
    /// User ID (for loading sessions from database)
    persistence_user_id: Option<uuid::Uuid>,
    /// Agent IDï¼ˆç”¨äºä»æ•°æ®åº“åŠ è½½ä¼šè¯ï¼‰
    /// Agent ID (for loading sessions from database)
    persistence_agent_id: Option<uuid::Uuid>,
}

/// LLM Agent äº‹ä»¶å¤„ç†å™¨
/// LLM Agent event handler
///
/// å…è®¸ç”¨æˆ·è‡ªå®šä¹‰äº‹ä»¶å¤„ç†é€»è¾‘
/// Allows users to customize event processing logic
#[async_trait::async_trait]
pub trait LLMAgentEventHandler: Send + Sync {
    /// Clone this handler trait object
    fn clone_box(&self) -> Box<dyn LLMAgentEventHandler>;

    /// è·å– Any ç±»å‹ç”¨äº downcasting
    /// Get Any type for downcasting
    fn as_any(&self) -> &dyn std::any::Any;

    /// å¤„ç†ç”¨æˆ·æ¶ˆæ¯å‰çš„é’©å­
    /// Hook before processing user message
    async fn before_chat(&self, message: &str) -> LLMResult<Option<String>> {
        Ok(Some(message.to_string()))
    }

    /// å¤„ç†ç”¨æˆ·æ¶ˆæ¯å‰çš„é’©å­ï¼ˆå¸¦æ¨¡å‹åç§°ï¼‰
    /// Hook before processing user message (with model name)
    ///
    /// é»˜è®¤å®ç°è°ƒç”¨ `before_chat`ã€‚
    /// Default implementation calls `before_chat`.
    /// å¦‚æœéœ€è¦çŸ¥é“ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆä¾‹å¦‚ç”¨äºæŒä¹…åŒ–ï¼‰ï¼Œè¯·å®ç°æ­¤æ–¹æ³•ã€‚
    /// If you need to know the model name (e.g., for persistence), implement this method.
    async fn before_chat_with_model(
        &self,
        message: &str,
        _model: &str,
    ) -> LLMResult<Option<String>> {
        self.before_chat(message).await
    }

    /// å¤„ç† LLM å“åº”åçš„é’©å­
    /// Hook after processing LLM response
    async fn after_chat(&self, response: &str) -> LLMResult<Option<String>> {
        Ok(Some(response.to_string()))
    }

    /// å¤„ç† LLM å“åº”åçš„é’©å­ï¼ˆå¸¦å…ƒæ•°æ®ï¼‰
    /// Hook after processing LLM response (with metadata)
    ///
    /// é»˜è®¤å®ç°è°ƒç”¨ after_chatã€‚
    /// Default implementation calls after_chat.
    /// å¦‚æœéœ€è¦è®¿é—®å“åº”å…ƒæ•°æ®ï¼ˆå¦‚ response_id, model, token countsï¼‰ï¼Œè¯·å®ç°æ­¤æ–¹æ³•ã€‚
    /// If you need to access response metadata (e.g., response_id, model, token counts), implement this method.
    async fn after_chat_with_metadata(
        &self,
        response: &str,
        _metadata: &super::types::LLMResponseMetadata,
    ) -> LLMResult<Option<String>> {
        self.after_chat(response).await
    }

    /// å¤„ç†å·¥å…·è°ƒç”¨
    /// Handle tool calls
    async fn on_tool_call(&self, name: &str, arguments: &str) -> LLMResult<Option<String>> {
        let _ = (name, arguments);
        Ok(None)
    }

    /// å¤„ç†é”™è¯¯
    /// Handle errors
    async fn on_error(&self, error: &LLMError) -> LLMResult<Option<String>> {
        let _ = error;
        Ok(None)
    }
}

impl Clone for Box<dyn LLMAgentEventHandler> {
    fn clone(&self) -> Self {
        self.clone_box()
    }
}

impl LLMAgent {
    /// åˆ›å»ºæ–°çš„ LLM Agent
    /// Create new LLM Agent
    pub fn new(config: LLMAgentConfig, provider: Arc<dyn LLMProvider>) -> Self {
        Self::with_initial_session(config, provider, None)
    }

    /// åˆ›å»ºæ–°çš„ LLM Agentï¼Œå¹¶æŒ‡å®šåˆå§‹ä¼šè¯ ID
    /// Create new LLM Agent and specify initial session ID
    ///
    /// # å‚æ•°
    /// # Parameters
    /// - `config`: Agent é…ç½®
    /// - `config`: Agent configuration
    /// - `provider`: LLM Provider
    /// - `initial_session_id`: åˆå§‹ä¼šè¯ IDï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„ ID
    /// - `initial_session_id`: Initial session ID; if None, an auto-generated ID is used
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// let agent = LLMAgent::with_initial_session(
    ///     config,
    ///     provider,
    ///     Some("user-session-001".to_string())
    /// );
    /// ```
    pub fn with_initial_session(
        config: LLMAgentConfig,
        provider: Arc<dyn LLMProvider>,
        initial_session_id: Option<String>,
    ) -> Self {
        let client = LLMClient::new(provider.clone());

        let mut session = if let Some(sid) = initial_session_id {
            ChatSession::with_id_str(&sid, LLMClient::new(provider.clone()))
        } else {
            ChatSession::new(LLMClient::new(provider.clone()))
        };

        // è®¾ç½®ç³»ç»Ÿæç¤º
        // Set system prompt
        if let Some(ref prompt) = config.system_prompt {
            session = session.with_system(prompt.clone());
        }

        // è®¾ç½®ä¸Šä¸‹æ–‡çª—å£å¤§å°
        // Set context window size
        session = session.with_context_window_size(config.context_window_size);

        let session_id = session.session_id().to_string();
        let session_arc = Arc::new(RwLock::new(session));

        // åˆå§‹åŒ–ä¼šè¯å­˜å‚¨
        // Initialize session storage
        let mut sessions = HashMap::new();
        sessions.insert(session_id.clone(), session_arc);

        // Clone fields needed for metadata before moving config
        let agent_id = config.agent_id.clone();
        let name = config.name.clone();

        // åˆ›å»º AgentCapabilities
        // Create AgentCapabilities
        let capabilities = mofa_kernel::agent::AgentCapabilities::builder()
            .tags(vec![
                "llm".to_string(),
                "chat".to_string(),
                "text-generation".to_string(),
                "multi-session".to_string(),
            ])
            .build();

        Self {
            config,
            metadata: AgentMetadata {
                id: agent_id,
                name,
                description: None,
                version: None,
                capabilities,
                state: AgentState::Created,
            },
            client,
            sessions: Arc::new(RwLock::new(sessions)),
            active_session_id: Arc::new(RwLock::new(session_id)),
            tools: Vec::new(),
            tool_executor: None,
            event_handler: None,
            plugins: Vec::new(),
            state: AgentState::Created,
            provider,
            prompt_plugin: None,
            tts_plugin: None,
            #[cfg(feature = "kokoro")]
            cached_kokoro_engine: Arc::new(Mutex::new(None)),
            active_tts_session: Arc::new(Mutex::new(None)),
            message_store: None,
            session_store: None,
            persistence_user_id: None,
            persistence_agent_id: None,
        }
    }

    /// åˆ›å»ºæ–°çš„ LLM Agentï¼Œå¹¶å°è¯•ä»æ•°æ®åº“åŠ è½½åˆå§‹ä¼šè¯ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰
    /// Create new LLM Agent and try to load initial session from database (async version)
    ///
    /// å¦‚æœæä¾›äº† persistence stores ä¸” session_id å­˜åœ¨äºæ•°æ®åº“ä¸­ï¼Œ
    /// If persistence stores are provided and session_id exists in database,
    /// ä¼šè‡ªåŠ¨åŠ è½½å†å²æ¶ˆæ¯å¹¶åº”ç”¨æ»‘åŠ¨çª—å£ã€‚
    /// historical messages will be loaded and sliding window applied automatically.
    ///
    /// # å‚æ•°
    /// # Parameters
    /// - `config`: Agent é…ç½®
    /// - `config`: Agent configuration
    /// - `provider`: LLM Provider
    /// - `initial_session_id`: åˆå§‹ä¼šè¯ IDï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„ ID
    /// - `initial_session_id`: Initial session ID; if None, an auto-generated ID is used
    /// - `message_store`: æ¶ˆæ¯å­˜å‚¨ï¼ˆå¯é€‰ï¼Œç”¨äºä»æ•°æ®åº“åŠ è½½å†å²ï¼‰
    /// - `message_store`: Message store (optional, for loading history from database)
    /// - `session_store`: ä¼šè¯å­˜å‚¨ï¼ˆå¯é€‰ï¼Œç”¨äºä»æ•°æ®åº“åŠ è½½å†å²ï¼‰
    /// - `session_store`: Session store (optional, for loading history from database)
    /// - `persistence_user_id`: ç”¨æˆ· IDï¼ˆç”¨äºä»æ•°æ®åº“åŠ è½½ä¼šè¯ï¼‰
    /// - `persistence_user_id`: User ID (for loading session from database)
    /// - `persistence_agent_id`: Agent IDï¼ˆç”¨äºä»æ•°æ®åº“åŠ è½½ä¼šè¯ï¼‰
    /// - `persistence_agent_id`: Agent ID (for loading session from database)
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// let agent = LLMAgent::with_initial_session_async(
    ///     config,
    ///     provider,
    ///     Some("user-session-001".to_string()),
    ///     Some(message_store),
    ///     Some(session_store),
    ///     Some(user_id),
    ///     Some(agent_id),
    /// ).await?;
    /// ```
    #[allow(clippy::too_many_arguments)]
    pub async fn with_initial_session_async(
        config: LLMAgentConfig,
        provider: Arc<dyn LLMProvider>,
        initial_session_id: Option<String>,
        message_store: Option<Arc<dyn crate::persistence::MessageStore + Send + Sync>>,
        session_store: Option<Arc<dyn crate::persistence::SessionStore + Send + Sync>>,
        persistence_user_id: Option<uuid::Uuid>,
        persistence_tenant_id: Option<uuid::Uuid>,
        persistence_agent_id: Option<uuid::Uuid>,
    ) -> Self {
        let client = LLMClient::new(provider.clone());

        // Clone initial_session_id to avoid move issues
        let initial_session_id_clone = initial_session_id.clone();

        // 1. å°è¯•ä»æ•°æ®åº“åŠ è½½ä¼šè¯ï¼ˆå¦‚æœæœ‰ stores ä¸”æŒ‡å®šäº† session_idï¼‰
        // 1. Try to load session from database (if stores are present and session_id specified)
        let session = if let (
            Some(sid),
            Some(msg_store),
            Some(sess_store),
            Some(user_id),
            Some(tenant_id),
            Some(agent_id),
        ) = (
            initial_session_id_clone,
            message_store.clone(),
            session_store.clone(),
            persistence_user_id,
            persistence_tenant_id,
            persistence_agent_id,
        ) {
            // Clone stores before moving them into ChatSession::load
            let msg_store_clone = msg_store.clone();
            let sess_store_clone = sess_store.clone();

            let session_uuid = uuid::Uuid::parse_str(&sid).unwrap_or_else(|_| {
                tracing::warn!(
                    "âš ï¸ Invalid session_id format '{}', generating a new UUID",
                    sid
                );
                // âš ï¸ Invalid session_id format '{}', will generate new UUID
                uuid::Uuid::now_v7()
            });

            // å°è¯•ä»æ•°æ®åº“åŠ è½½
            // Try loading from database
            match ChatSession::load(
                session_uuid,
                LLMClient::new(provider.clone()),
                user_id,
                agent_id,
                tenant_id,
                msg_store,
                sess_store,
                config.context_window_size,
            )
            .await
            {
                Ok(loaded_session) => {
                    tracing::info!(
                        "âœ… Session loaded from database: {} ({} messages)",
                        // âœ… Session loaded from database: {} ({} messages)
                        sid,
                        loaded_session.messages().len()
                    );
                    loaded_session
                }
                Err(e) => {
                    // ä¼šè¯ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°ä¼šè¯ï¼ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„IDå’Œä»persistenceè·å–çš„user_id/agent_idï¼‰
                    // Session not found; create new session (using specified ID and user_id/agent_id from persistence)
                    tracing::info!(
                        "ğŸ“ Creating new session and persisting: {} (not found in DB: {})",
                        sid,
                        e
                    );
                    // ğŸ“ Creating new session and persisting: {} (doesn't exist in DB: {})

                    // Clone stores again for the fallback case
                    let msg_store_clone2 = msg_store_clone.clone();
                    let sess_store_clone2 = sess_store_clone.clone();

                    // ä½¿ç”¨æ­£ç¡®çš„ user_id å’Œ agent_id åˆ›å»ºä¼šè¯ï¼Œå¹¶æŒä¹…åŒ–åˆ°æ•°æ®åº“
                    // Create session with correct user_id and agent_id, and persist to database
                    match ChatSession::with_id_and_stores_and_persist(
                        session_uuid,
                        LLMClient::new(provider.clone()),
                        user_id,
                        agent_id,
                        tenant_id,
                        msg_store_clone,
                        sess_store_clone,
                        config.context_window_size,
                    )
                    .await
                    {
                        Ok(mut new_session) => {
                            if let Some(ref prompt) = config.system_prompt {
                                new_session = new_session.with_system(prompt.clone());
                            }
                            new_session
                        }
                        Err(persist_err) => {
                            tracing::error!(
                                "âŒ Failed to persist session: {}, falling back to in-memory session",
                                persist_err
                            );
                            // âŒ Persisting session failed: {}, falling back to in-memory session
                            // é™çº§ï¼šå¦‚æœæŒä¹…åŒ–å¤±è´¥ï¼Œåˆ›å»ºå†…å­˜ä¼šè¯
                            // Fallback: If persistence fails, create in-memory session
                            let new_session = ChatSession::with_id_and_stores(
                                session_uuid,
                                LLMClient::new(provider.clone()),
                                user_id,
                                agent_id,
                                tenant_id,
                                msg_store_clone2,
                                sess_store_clone2,
                                config.context_window_size,
                            );
                            if let Some(ref prompt) = config.system_prompt {
                                new_session.with_system(prompt.clone())
                            } else {
                                new_session
                            }
                        }
                    }
                }
            }
        } else {
            // æ²¡æœ‰ persistence storesï¼Œåˆ›å»ºæ™®é€šä¼šè¯
            // No persistence stores; creating standard session
            let mut session = if let Some(sid) = initial_session_id {
                ChatSession::with_id_str(&sid, LLMClient::new(provider.clone()))
            } else {
                ChatSession::new(LLMClient::new(provider.clone()))
            };
            if let Some(ref prompt) = config.system_prompt {
                session = session.with_system(prompt.clone());
            }
            session.with_context_window_size(config.context_window_size)
        };

        let session_id = session.session_id().to_string();
        let session_arc = Arc::new(RwLock::new(session));

        // åˆå§‹åŒ–ä¼šè¯å­˜å‚¨
        // Initialize session storage
        let mut sessions = HashMap::new();
        sessions.insert(session_id.clone(), session_arc);

        // Clone fields needed for metadata before moving config
        let agent_id = config.agent_id.clone();
        let name = config.name.clone();

        // åˆ›å»º AgentCapabilities
        // Create AgentCapabilities
        let capabilities = mofa_kernel::agent::AgentCapabilities::builder()
            .tags(vec![
                "llm".to_string(),
                "chat".to_string(),
                "text-generation".to_string(),
                "multi-session".to_string(),
            ])
            .build();

        Self {
            config,
            metadata: AgentMetadata {
                id: agent_id,
                name,
                description: None,
                version: None,
                capabilities,
                state: AgentState::Created,
            },
            client,
            sessions: Arc::new(RwLock::new(sessions)),
            active_session_id: Arc::new(RwLock::new(session_id)),
            tools: Vec::new(),
            tool_executor: None,
            event_handler: None,
            plugins: Vec::new(),
            state: AgentState::Created,
            provider,
            prompt_plugin: None,
            tts_plugin: None,
            #[cfg(feature = "kokoro")]
            cached_kokoro_engine: Arc::new(Mutex::new(None)),
            active_tts_session: Arc::new(Mutex::new(None)),
            message_store,
            session_store,
            persistence_user_id,
            persistence_agent_id,
        }
    }

    /// è·å–é…ç½®
    /// Get configuration
    pub fn config(&self) -> &LLMAgentConfig {
        &self.config
    }

    /// è·å– LLM Client
    /// Get LLM Client
    pub fn client(&self) -> &LLMClient {
        &self.client
    }

    // ========================================================================
    // ä¼šè¯ç®¡ç†æ–¹æ³•
    // Session management methods
    // ========================================================================

    /// è·å–å½“å‰æ´»åŠ¨ä¼šè¯ID
    /// Get current active session ID
    pub async fn current_session_id(&self) -> String {
        self.active_session_id.read().await.clone()
    }

    /// åˆ›å»ºæ–°ä¼šè¯
    /// Create new session
    ///
    /// è¿”å›æ–°ä¼šè¯çš„ session_id
    /// Returns the session_id of the new session
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// let session_id = agent.create_session().await;
    /// agent.chat_with_session(&session_id, "Hello").await?;
    /// ```
    pub async fn create_session(&self) -> String {
        let mut session = ChatSession::new(LLMClient::new(self.provider.clone()));

        // ä½¿ç”¨åŠ¨æ€ Prompt æ¨¡æ¿ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        // Use dynamic Prompt template (if available)
        let mut system_prompt = self.config.system_prompt.clone();

        if let Some(ref plugin) = self.prompt_plugin
            && let Some(template) = plugin.get_current_template().await
        {
            // æ¸²æŸ“é»˜è®¤æ¨¡æ¿
            // Render default template
            system_prompt = match template.render(&[]) {
                Ok(prompt) => Some(prompt),
                Err(_) => self.config.system_prompt.clone(),
            };
        }

        if let Some(ref prompt) = system_prompt {
            session = session.with_system(prompt.clone());
        }

        // è®¾ç½®ä¸Šä¸‹æ–‡çª—å£å¤§å°
        // Set context window size
        session = session.with_context_window_size(self.config.context_window_size);

        let session_id = session.session_id().to_string();
        let session_arc = Arc::new(RwLock::new(session));

        let mut sessions = self.sessions.write().await;
        sessions.insert(session_id.clone(), session_arc);

        session_id
    }

    /// ä½¿ç”¨æŒ‡å®šIDåˆ›å»ºæ–°ä¼šè¯
    /// Create new session with specified ID
    ///
    /// å¦‚æœ session_id å·²å­˜åœ¨ï¼Œè¿”å›é”™è¯¯
    /// Returns error if session_id already exists
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// let session_id = agent.create_session_with_id("user-123-session").await?;
    /// ```
    pub async fn create_session_with_id(&self, session_id: impl Into<String>) -> LLMResult<String> {
        let session_id = session_id.into();

        {
            let sessions = self.sessions.read().await;
            if sessions.contains_key(&session_id) {
                return Err(LLMError::Other(format!(
                    "Session with id '{}' already exists",
                    session_id
                )));
            }
        }

        let mut session =
            ChatSession::with_id_str(&session_id, LLMClient::new(self.provider.clone()));

        // ä½¿ç”¨åŠ¨æ€ Prompt æ¨¡æ¿ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        // Use dynamic Prompt template (if available)
        let mut system_prompt = self.config.system_prompt.clone();

        if let Some(ref plugin) = self.prompt_plugin
            && let Some(template) = plugin.get_current_template().await
        {
            // æ¸²æŸ“é»˜è®¤æ¨¡æ¿
            // Render default template
            system_prompt = match template.render(&[]) {
                Ok(prompt) => Some(prompt),
                Err(_) => self.config.system_prompt.clone(),
            };
        }

        if let Some(ref prompt) = system_prompt {
            session = session.with_system(prompt.clone());
        }

        // è®¾ç½®ä¸Šä¸‹æ–‡çª—å£å¤§å°
        // Set context window size
        session = session.with_context_window_size(self.config.context_window_size);

        let session_arc = Arc::new(RwLock::new(session));

        let mut sessions = self.sessions.write().await;
        sessions.insert(session_id.clone(), session_arc);

        Ok(session_id)
    }

    /// åˆ‡æ¢å½“å‰æ´»åŠ¨ä¼šè¯
    /// Switch current active session
    ///
    /// # é”™è¯¯
    /// # Error
    /// å¦‚æœ session_id ä¸å­˜åœ¨åˆ™è¿”å›é”™è¯¯
    /// Returns error if session_id does not exist
    pub async fn switch_session(&self, session_id: &str) -> LLMResult<()> {
        let sessions = self.sessions.read().await;
        if !sessions.contains_key(session_id) {
            return Err(LLMError::Other(format!(
                "Session '{}' not found",
                session_id
            )));
        }
        drop(sessions);

        let mut active = self.active_session_id.write().await;
        *active = session_id.to_string();
        Ok(())
    }

    /// è·å–æˆ–åˆ›å»ºä¼šè¯
    /// Get or create session
    ///
    /// å¦‚æœ session_id å­˜åœ¨åˆ™è¿”å›å®ƒï¼Œå¦åˆ™ä½¿ç”¨è¯¥ ID åˆ›å»ºæ–°ä¼šè¯
    /// Returns session_id if it exists, otherwise creates a new session with that ID
    pub async fn get_or_create_session(&self, session_id: impl Into<String>) -> String {
        let session_id = session_id.into();

        {
            let sessions = self.sessions.read().await;
            if sessions.contains_key(&session_id) {
                return session_id;
            }
        }

        // ä¼šè¯ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„
        // Session not found, creating new one
        let _ = self.create_session_with_id(&session_id).await;
        session_id
    }

    /// åˆ é™¤ä¼šè¯
    /// Remove session
    ///
    /// # æ³¨æ„
    /// # Note
    /// ä¸èƒ½åˆ é™¤å½“å‰æ´»åŠ¨ä¼šè¯ï¼Œéœ€è¦å…ˆåˆ‡æ¢åˆ°å…¶ä»–ä¼šè¯
    /// Cannot remove active session; switch to another session first
    pub async fn remove_session(&self, session_id: &str) -> LLMResult<()> {
        let active = self.active_session_id.read().await.clone();
        if active == session_id {
            return Err(LLMError::Other(
                "Cannot remove active session. Switch to another session first.".to_string(),
            ));
        }

        let mut sessions = self.sessions.write().await;
        if sessions.remove(session_id).is_none() {
            return Err(LLMError::Other(format!(
                "Session '{}' not found",
                session_id
            )));
        }

        Ok(())
    }

    /// åˆ—å‡ºæ‰€æœ‰ä¼šè¯ID
    /// List all session IDs
    pub async fn list_sessions(&self) -> Vec<String> {
        let sessions = self.sessions.read().await;
        sessions.keys().cloned().collect()
    }

    /// è·å–ä¼šè¯æ•°é‡
    /// Get session count
    pub async fn session_count(&self) -> usize {
        let sessions = self.sessions.read().await;
        sessions.len()
    }

    /// æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨
    /// Check if session exists
    pub async fn has_session(&self, session_id: &str) -> bool {
        let sessions = self.sessions.read().await;
        sessions.contains_key(session_id)
    }

    // ========================================================================
    // TTS ä¾¿æ·æ–¹æ³•
    // TTS convenience methods
    // ========================================================================

    /// ä½¿ç”¨ TTS åˆæˆå¹¶æ’­æ”¾æ–‡æœ¬
    /// Synthesize and play text using TTS
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// agent.tts_speak("Hello world").await?;
    /// ```
    pub async fn tts_speak(&self, text: &str) -> LLMResult<()> {
        let tts = self
            .tts_plugin
            .as_ref()
            .ok_or_else(|| LLMError::Other("TTS plugin not configured".to_string()))?;

        let mut tts_guard = tts.lock().await;
        tts_guard
            .synthesize_and_play(text)
            .await
            .map_err(|e| LLMError::Other(format!("TTS synthesis failed: {}", e)))
    }

    /// ä½¿ç”¨ TTS æµå¼åˆæˆæ–‡æœ¬
    /// Synthesize text in a stream using TTS
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// agent.tts_speak_streaming("Hello world", Box::new(|audio| {
    ///     println!("Got {} bytes of audio", audio.len());
    /// })).await?;
    /// ```
    pub async fn tts_speak_streaming(
        &self,
        text: &str,
        callback: Box<dyn Fn(Vec<u8>) + Send + Sync>,
    ) -> LLMResult<()> {
        let tts = self
            .tts_plugin
            .as_ref()
            .ok_or_else(|| LLMError::Other("TTS plugin not configured".to_string()))?;

        let mut tts_guard = tts.lock().await;
        tts_guard
            .synthesize_streaming(text, callback)
            .await
            .map_err(|e| LLMError::Other(format!("TTS streaming failed: {}", e)))
    }

    /// ä½¿ç”¨ TTS æµå¼åˆæˆæ–‡æœ¬ï¼ˆf32 native formatï¼Œæ›´é«˜æ•ˆï¼‰
    /// Stream synthesize text using TTS (f32 native format, more efficient)
    ///
    /// This method is more efficient for KokoroTTS as it uses the native f32 format
    /// without the overhead of f32 -> i16 -> u8 conversion.
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// use rodio::buffer::SamplesBuffer;
    ///
    /// agent.tts_speak_f32_stream("Hello world", Box::new(|audio_f32| {
    ///     // audio_f32 is Vec<f32> with values in [-1.0, 1.0]
    ///     sink.append(SamplesBuffer::new(1, 24000, audio_f32));
    /// })).await?;
    /// ```
    pub async fn tts_speak_f32_stream(
        &self,
        text: &str,
        callback: Box<dyn Fn(Vec<f32>) + Send + Sync>,
    ) -> LLMResult<()> {
        let tts = self
            .tts_plugin
            .as_ref()
            .ok_or_else(|| LLMError::Other("TTS plugin not configured".to_string()))?;

        let mut tts_guard = tts.lock().await;
        tts_guard
            .synthesize_streaming_f32(text, callback)
            .await
            .map_err(|e| LLMError::Other(format!("TTS f32 streaming failed: {}", e)))
    }

    /// è·å– TTS éŸ³é¢‘æµï¼ˆä»…æ”¯æŒ Kokoro TTSï¼‰
    /// Get TTS audio stream (only Kokoro TTS supported)
    ///
    /// Returns a direct stream of (audio_f32, duration) tuples from KokoroTTS.
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// use futures::StreamExt;
    /// use rodio::buffer::SamplesBuffer;
    ///
    /// if let Ok(mut stream) = agent.tts_create_stream("Hello world").await {
    ///     while let Some((audio, took)) = stream.next().await {
    ///         // audio is Vec<f32> with values in [-1.0, 1.0]
    ///         sink.append(SamplesBuffer::new(1, 24000, audio));
    ///     }
    /// }
    /// ```
    pub async fn tts_create_stream(&self, text: &str) -> LLMResult<TtsAudioStream> {
        #[cfg(feature = "kokoro")]
        {
            use mofa_plugins::tts::kokoro_wrapper::KokoroTTS;

            // é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„å¼•æ“ï¼ˆåªéœ€åˆå§‹åŒ–ä¸€æ¬¡ï¼‰
            // First check if there's a cached engine (initializes only once)
            let cached_engine = {
                let cache_guard = self.cached_kokoro_engine.lock().await;
                cache_guard.clone()
            };

            let kokoro = if let Some(engine) = cached_engine {
                // ä½¿ç”¨ç¼“å­˜çš„å¼•æ“ï¼ˆæ— éœ€å†æ¬¡è·å– tts_plugin çš„é”ï¼‰
                // Use cached engine (no need to re-acquire tts_plugin lock)
                engine
            } else {
                // é¦–æ¬¡è°ƒç”¨ï¼šè·å– tts_plugin çš„é”ï¼Œdowncast å¹¶ç¼“å­˜
                // First call: acquire tts_plugin lock, downcast, and cache
                let tts = self
                    .tts_plugin
                    .as_ref()
                    .ok_or_else(|| LLMError::Other("TTS plugin not configured".to_string()))?;

                let tts_guard = tts.lock().await;

                let engine = tts_guard
                    .engine()
                    .ok_or_else(|| LLMError::Other("TTS engine not initialized".to_string()))?;

                if let Some(kokoro_ref) = engine.as_any().downcast_ref::<KokoroTTS>() {
                    // å…‹éš† KokoroTTSï¼ˆå†…éƒ¨ä½¿ç”¨ Arcï¼Œå…‹éš†åªæ˜¯å¢åŠ å¼•ç”¨è®¡æ•°ï¼‰
                    // Clone KokoroTTS (uses Arc internally, cloning just increases ref count)
                    let cloned = kokoro_ref.clone();
                    let cloned_arc = Arc::new(cloned);

                    // è·å– voice é…ç½®
                    // Get voice configuration
                    let voice = tts_guard
                        .stats()
                        .get("default_voice")
                        .and_then(|v| v.as_str())
                        .unwrap_or("default");

                    // ç¼“å­˜å…‹éš†çš„å¼•æ“
                    // Cache the cloned engine
                    {
                        let mut cache_guard = self.cached_kokoro_engine.lock().await;
                        *cache_guard = Some(cloned_arc.clone());
                    }

                    cloned_arc
                } else {
                    return Err(LLMError::Other("TTS engine is not KokoroTTS".to_string()));
                }
            };

            // ä½¿ç”¨ç¼“å­˜çš„å¼•æ“åˆ›å»º streamï¼ˆæ— éœ€å†æ¬¡è·å– tts_plugin çš„é”ï¼‰
            // Create stream using cached engine (no need to re-acquire tts_plugin lock)
            let voice = "default"; // å¯ä»¥ä»é…ç½®ä¸­è·å–
            // voice = "default"; // Can be retrieved from configuration
            let (mut sink, stream) = kokoro
                .create_stream(voice)
                .await
                .map_err(|e| LLMError::Other(format!("Failed to create TTS stream: {}", e)))?;

            // Submit text for synthesis
            sink.synth(text.to_string()).await.map_err(|e| {
                LLMError::Other(format!("Failed to submit text for synthesis: {}", e))
            })?;

            // Box the stream to hide the concrete type
            Ok(Box::pin(stream))
        }

        #[cfg(not(feature = "kokoro"))]
        {
            Err(LLMError::Other("Kokoro feature not enabled".to_string()))
        }
    }

    /// Stream multiple sentences through a single TTS stream
    ///
    /// This is more efficient than calling tts_speak_f32_stream multiple times
    /// because it reuses the same stream for all sentences, following the kokoro-tts
    /// streaming pattern: ONE stream, multiple synth calls, continuous audio output.
    ///
    /// # Arguments
    /// - `sentences`: Vector of text sentences to synthesize
    /// - `callback`: Function to call with each audio chunk (Vec<f32>)
    ///
    /// # Example
    /// ```rust,ignore
    /// use rodio::buffer::SamplesBuffer;
    ///
    /// let sentences = vec!["Hello".to_string(), "World".to_string()];
    /// agent.tts_speak_f32_stream_batch(
    ///     sentences,
    ///     Box::new(|audio_f32| {
    ///         sink.append(SamplesBuffer::new(1, 24000, audio_f32));
    ///     }),
    /// ).await?;
    /// ```
    pub async fn tts_speak_f32_stream_batch(
        &self,
        sentences: Vec<String>,
        callback: Box<dyn Fn(Vec<f32>) + Send + Sync>,
    ) -> LLMResult<()> {
        let tts = self
            .tts_plugin
            .as_ref()
            .ok_or_else(|| LLMError::Other("TTS plugin not configured".to_string()))?;

        let tts_guard = tts.lock().await;

        #[cfg(feature = "kokoro")]
        {
            use mofa_plugins::tts::kokoro_wrapper::KokoroTTS;

            let engine = tts_guard
                .engine()
                .ok_or_else(|| LLMError::Other("TTS engine not initialized".to_string()))?;

            if let Some(kokoro) = engine.as_any().downcast_ref::<KokoroTTS>() {
                let voice = tts_guard
                    .stats()
                    .get("default_voice")
                    .and_then(|v| v.as_str())
                    .unwrap_or("default")
                    .to_string();

                // Create ONE stream for all sentences
                let (mut sink, mut stream) = kokoro
                    .create_stream(&voice)
                    .await
                    .map_err(|e| LLMError::Other(format!("Failed to create TTS stream: {}", e)))?;

                // Spawn a task to consume the stream continuously
                tokio::spawn(async move {
                    while let Some((audio, _took)) = stream.next().await {
                        callback(audio);
                    }
                });

                // Submit all sentences to the same sink
                for sentence in sentences {
                    sink.synth(sentence)
                        .await
                        .map_err(|e| LLMError::Other(format!("Failed to submit text: {}", e)))?;
                }

                return Ok(());
            }

            Err(LLMError::Other("TTS engine is not KokoroTTS".to_string()))
        }

        #[cfg(not(feature = "kokoro"))]
        {
            Err(LLMError::Other("Kokoro feature not enabled".to_string()))
        }
    }

    /// æ£€æŸ¥æ˜¯å¦é…ç½®äº† TTS æ’ä»¶
    /// Check if the TTS plugin is configured
    pub fn has_tts(&self) -> bool {
        self.tts_plugin.is_some()
    }

    /// Interrupt currently playing TTS audio
    ///
    /// Stops current audio playback and cancels any ongoing TTS synthesis.
    /// Call this before starting a new TTS request for clean transition.
    ///
    /// # Example
    /// ```rust,ignore
    /// // User enters new input while audio is playing
    /// agent.interrupt_tts().await?;
    /// agent.chat_with_tts(&session_id, new_input).await?;
    /// ```
    pub async fn interrupt_tts(&self) -> LLMResult<()> {
        let mut session_guard = self.active_tts_session.lock().await;
        if let Some(session) = session_guard.take() {
            session.cancel();
        }
        Ok(())
    }

    // ========================================================================
    // LLM + TTS æµå¼å¯¹è¯æ–¹æ³•
    // LLM + TTS Streaming Dialogue Methods
    // ========================================================================

    /// æµå¼èŠå¤©å¹¶è‡ªåŠ¨ TTS æ’­æ”¾ï¼ˆæœ€ç®€ç‰ˆæœ¬ï¼‰
    /// Streaming chat with automatic TTS playback (simplest version)
    ///
    /// è‡ªåŠ¨å¤„ç†ï¼š
    /// Automatic processing:
    /// - æµå¼ LLM è¾“å‡º
    /// - Streaming LLM output
    /// - æŒ‰æ ‡ç‚¹æ–­å¥
    /// - Sentence segmenting by punctuation
    /// - æ‰¹é‡ TTS æ’­æ”¾
    /// - Batch TTS playback
    ///
    /// # ç¤ºä¾‹
    /// # Example
    /// ```rust,ignore
    /// agent.chat_with_tts(&session_id, "ä½ å¥½").await?;
    /// ```
    pub async fn chat_with_tts(
        &self,
        session_id: &str,
        message: impl Into<String>,
    ) -> LLMResult<()> {
        self.chat_with_tts_internal(session_id, message, None).await
    }

    /// æµå¼èŠå¤©å¹¶è‡ªåŠ¨ TTS æ’­æ”¾ï¼ˆè‡ªå®šä¹‰éŸ³é¢‘å¤„ç†ï¼‰
    /// Streaming chat with automatic TTS playback (custom audio processing)
    ///
    /// # ç¤ºä¾‹
    /// # Example
    /// ```rust,ignore
    /// use rodio::buffer::SamplesBuffer;
    ///
    /// agent.chat_with_tts_callback(&session_id, "ä½ å¥½", |audio| {
    ///     sink.append(SamplesBuffer::new(1, 24000, audio));
    /// }).await?;
    /// ```
    pub async fn chat_with_tts_callback(
        &self,
        session_id: &str,
        message: impl Into<String>,
        callback: impl Fn(Vec<f32>) + Send + Sync + 'static,
    ) -> LLMResult<()> {
        self.chat_with_tts_internal(session_id, message, Some(Box::new(callback)))
            .await
    }

    /// åˆ›å»ºå®æ—¶ TTS æµ
    /// Create a real-time TTS stream
    ///
    /// è¿”å›çš„ handle å…è®¸ incremental æäº¤æ–‡æœ¬ï¼Œå®ç°çœŸæ­£çš„å®æ—¶æµå¼ TTSã€‚
    /// The returned handle allows incremental text submission for true streaming TTS.
    ///
    /// # æ ¸å¿ƒæœºåˆ¶
    /// # Core Mechanism
    /// 1. åˆ›å»º TTS streamï¼ˆä»…ä¸€æ¬¡ï¼‰
    /// 1. Create TTS stream (only once)
    /// 2. å¯åŠ¨æ¶ˆè´¹è€…ä»»åŠ¡ï¼ˆæŒç»­æ¥æ”¶éŸ³é¢‘å—ï¼‰
    /// 2. Start consumer task (continuously receiving audio chunks)
    /// 3. è¿”å›çš„ sink æ”¯æŒå¤šæ¬¡ `synth()` è°ƒç”¨
    /// 3. The returned sink supports multiple `synth()` calls
    #[cfg(feature = "kokoro")]
    async fn create_tts_stream_handle(
        &self,
        callback: Box<dyn Fn(Vec<f32>) + Send + Sync>,
        cancellation_token: Option<CancellationToken>,
    ) -> LLMResult<TTSStreamHandle> {
        use mofa_plugins::tts::kokoro_wrapper::KokoroTTS;

        let tts = self
            .tts_plugin
            .as_ref()
            .ok_or_else(|| LLMError::Other("TTS plugin not configured".to_string()))?;

        let tts_guard = tts.lock().await;
        let engine = tts_guard
            .engine()
            .ok_or_else(|| LLMError::Other("TTS engine not initialized".to_string()))?;

        let kokoro = engine
            .as_any()
            .downcast_ref::<KokoroTTS>()
            .ok_or_else(|| LLMError::Other("TTS engine is not KokoroTTS".to_string()))?;

        let voice = tts_guard
            .stats()
            .get("default_voice")
            .and_then(|v| v.as_str())
            .unwrap_or("default")
            .to_string();

        // åˆ›å»º TTS streamï¼ˆåªåˆ›å»ºä¸€æ¬¡ï¼‰
        // Create TTS stream (only created once)
        let (sink, mut stream) = kokoro
            .create_stream(&voice)
            .await
            .map_err(|e| LLMError::Other(format!("Failed to create TTS stream: {}", e)))?;

        // Clone cancellation token for the spawned task
        let token_clone = cancellation_token.as_ref().map(|t| t.clone_token());

        // å¯åŠ¨æ¶ˆè´¹è€…ä»»åŠ¡ï¼ˆæŒç»­æ¥æ”¶éŸ³é¢‘å—ï¼Œæ”¯æŒå–æ¶ˆæ£€æŸ¥ï¼‰
        // Start consumer task (receiving audio chunks with cancellation support)
        let stream_handle = tokio::spawn(async move {
            while let Some((audio, _took)) = stream.next().await {
                // æ£€æŸ¥å–æ¶ˆä¿¡å·
                // Check cancellation signal
                if let Some(ref token) = token_clone
                    && token.is_cancelled()
                {
                    break; // é€€å‡ºå¾ªç¯ï¼Œåœæ­¢éŸ³é¢‘å¤„ç†
                    // Exit loop, stop audio processing
                }
                callback(audio);
            }
        });

        Ok(TTSStreamHandle {
            sink,
            _stream_handle: stream_handle,
        })
    }

    /// å†…éƒ¨å®ç°ï¼šLLM + TTS å®æ—¶æµå¼å¯¹è¯
    /// Internal implementation: LLM + TTS real-time streaming dialogue
    ///
    /// # æ ¸å¿ƒæœºåˆ¶
    /// # Core Mechanism
    /// 1. åœ¨ LLM æµå¼è¾“å‡º**ä¹‹å‰**åˆ›å»º TTS stream
    /// 1. Create TTS stream BEFORE LLM streaming output
    /// 2. æ£€æµ‹åˆ°å®Œæ•´å¥å­æ—¶ç«‹å³æäº¤åˆ° TTS
    /// 2. Submit to TTS immediately when a full sentence is detected
    /// 3. LLM æµå’Œ TTS æµå¹¶è¡Œè¿è¡Œ
    /// 3. LLM stream and TTS stream run in parallel
    async fn chat_with_tts_internal(
        &self,
        session_id: &str,
        message: impl Into<String>,
        callback: Option<Box<dyn Fn(Vec<f32>) + Send + Sync>>,
    ) -> LLMResult<()> {
        #[cfg(feature = "kokoro")]
        {
            use mofa_plugins::tts::kokoro_wrapper::KokoroTTS;

            let callback = match callback {
                Some(cb) => cb,
                None => {
                    // æ—  TTS è¯·æ±‚ï¼Œä»…æµå¼è¾“å‡ºæ–‡æœ¬
                    // No TTS request, only stream text output
                    let mut text_stream =
                        self.chat_stream_with_session(session_id, message).await?;
                    while let Some(result) = text_stream.next().await {
                        match result {
                            Ok(text_chunk) => {
                                print!("{}", text_chunk);
                                std::io::stdout().flush().map_err(|e| {
                                    LLMError::Other(format!("Failed to flush stdout: {}", e))
                                })?;
                            }
                            Err(e) if e.to_string().contains("__stream_end__") => break,
                            Err(e) => return Err(e),
                        }
                    }
                    println!();
                    return Ok(());
                }
            };

            // Step 0: å–æ¶ˆä»»ä½•ç°æœ‰çš„ TTS ä¼šè¯
            // Step 0: Cancel any existing TTS sessions
            self.interrupt_tts().await?;

            // Step 1: åˆ›å»º cancellation token
            // Step 1: Create cancellation token
            let cancellation_token = CancellationToken::new();

            // Step 2: åœ¨ LLM æµå¼è¾“å‡ºä¹‹å‰åˆ›å»º TTS streamï¼ˆä¼ å…¥ cancellation tokenï¼‰
            // Step 2: Create TTS stream before LLM output (passing cancellation token)
            let mut tts_handle = self
                .create_tts_stream_handle(callback, Some(cancellation_token.clone_token()))
                .await?;

            // Step 3: åˆ›å»ºå¹¶è·Ÿè¸ªæ–°çš„ TTS session
            // Step 3: Create and track a new TTS session
            let session = TTSSession::new(cancellation_token);

            {
                let mut active_session = self.active_tts_session.lock().await;
                *active_session = Some(session);
            }

            let mut buffer = SentenceBuffer::new();

            // Step 4: æµå¼å¤„ç† LLM å“åº”ï¼Œå®æ—¶æäº¤å¥å­åˆ° TTS
            // Step 4: Stream LLM response, submitting sentences to TTS in real-time
            let mut text_stream = self.chat_stream_with_session(session_id, message).await?;

            while let Some(result) = text_stream.next().await {
                match result {
                    Ok(text_chunk) => {
                        // æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
                        // Check if it has been cancelled
                        {
                            let active_session = self.active_tts_session.lock().await;
                            if let Some(ref session) = *active_session
                                && !session.is_active()
                            {
                                return Ok(()); // ä¼˜é›…é€€å‡º
                                // Graceful exit
                            }
                        }

                        // å®æ—¶æ˜¾ç¤ºæ–‡æœ¬
                        // Display text in real-time
                        print!("{}", text_chunk);
                        std::io::stdout().flush().map_err(|e| {
                            LLMError::Other(format!("Failed to flush stdout: {}", e))
                        })?;

                        // æ£€æµ‹å¥å­å¹¶ç«‹å³æäº¤åˆ° TTS
                        // Detect sentence and submit to TTS immediately
                        if let Some(sentence) = buffer.push(&text_chunk)
                            && let Err(e) = tts_handle.sink.synth(sentence).await
                        {
                            eprintln!("[TTS Error] Failed to submit sentence: {}", e);
                            // ç»§ç»­æµå¼å¤„ç†ï¼Œå³ä½¿ TTS å¤±è´¥
                            // Continue streaming even if TTS fails
                        }
                    }
                    Err(e) if e.to_string().contains("__stream_end__") => break,
                    Err(e) => return Err(e),
                }
            }

            // Step 5: æäº¤å‰©ä½™æ–‡æœ¬
            // Step 5: Submit remaining text
            if let Some(remaining) = buffer.flush()
                && let Err(e) = tts_handle.sink.synth(remaining).await
            {
                eprintln!("[TTS Error] Failed to submit final sentence: {}", e);
            }

            // Step 6: æ¸…ç†ä¼šè¯
            // Step 6: Clean up the session
            {
                let mut active_session = self.active_tts_session.lock().await;
                *active_session = None;
            }

            // Step 7: ç­‰å¾… TTS æµå®Œæˆï¼ˆæ‰€æœ‰éŸ³é¢‘å—å¤„ç†å®Œæ¯•ï¼‰
            // Step 7: Wait for TTS stream completion (all audio blocks processed)
            let _ = tokio::time::timeout(
                tokio::time::Duration::from_secs(30),
                tts_handle._stream_handle,
            )
            .await
            .map_err(|_| LLMError::Other("TTS stream processing timeout".to_string()))
            .and_then(|r| r.map_err(|e| LLMError::Other(format!("TTS stream task failed: {}", e))));

            Ok(())
        }

        #[cfg(not(feature = "kokoro"))]
        {
            // å½“ kokoro feature æœªå¯ç”¨æ—¶ï¼Œä½¿ç”¨æ‰¹é‡å¤„ç†æ¨¡å¼
            // When kokoro feature is disabled, use batch processing mode
            let mut text_stream = self.chat_stream_with_session(session_id, message).await?;
            let mut buffer = SentenceBuffer::new();
            let mut sentences = Vec::new();

            // æ”¶é›†æ‰€æœ‰å¥å­
            // Collect all sentences
            while let Some(result) = text_stream.next().await {
                match result {
                    Ok(text_chunk) => {
                        print!("{}", text_chunk);
                        std::io::stdout().flush().map_err(|e| {
                            LLMError::Other(format!("Failed to flush stdout: {}", e))
                        })?;

                        if let Some(sentence) = buffer.push(&text_chunk) {
                            sentences.push(sentence);
                        }
                    }
                    Err(e) if e.to_string().contains("__stream_end__") => break,
                    Err(e) => return Err(e),
                }
            }

            // æ·»åŠ å‰©ä½™å†…å®¹
            // Add remaining content
            if let Some(remaining) = buffer.flush() {
                sentences.push(remaining);
            }

            // æ‰¹é‡æ’­æ”¾ TTSï¼ˆå¦‚æœæœ‰å›è°ƒï¼‰
            // Batch play TTS (if callback is provided)
            if !sentences.is_empty()
                && let Some(cb) = callback
            {
                for sentence in &sentences {
                    println!("\n[TTS] {}", sentence);
                }
                // æ³¨æ„ï¼šé kokoro ç¯å¢ƒä¸‹æ— æ³•è°ƒç”¨æ­¤æ–¹æ³•
                // Note: This method cannot be called in non-kokoro environments
                // è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µå¤„ç†
                // Needs to be handled according to actual situation here
                let _ = cb;
            }

            Ok(())
        }
    }

    /// å†…éƒ¨æ–¹æ³•ï¼šè·å–ä¼šè¯ Arc
    /// Internal method: Get session Arc
    async fn get_session_arc(&self, session_id: &str) -> LLMResult<Arc<RwLock<ChatSession>>> {
        let sessions = self.sessions.read().await;
        sessions
            .get(session_id)
            .cloned()
            .ok_or_else(|| LLMError::Other(format!("Session '{}' not found", session_id)))
    }

    // ========================================================================
    // å¯¹è¯æ–¹æ³•
    // Dialogue Methods
    // ========================================================================

    /// å‘é€æ¶ˆæ¯å¹¶è·å–å“åº”ï¼ˆä½¿ç”¨å½“å‰æ´»åŠ¨ä¼šè¯ï¼‰
    /// Send message and get response (using current active session)
    pub async fn chat(&self, message: impl Into<String>) -> LLMResult<String> {
        let session_id = self.active_session_id.read().await.clone();
        self.chat_with_session(&session_id, message).await
    }

    /// ä½¿ç”¨æŒ‡å®šä¼šè¯å‘é€æ¶ˆæ¯å¹¶è·å–å“åº”
    /// Send message and get response using specified session
    ///
    /// # å‚æ•°
    /// # Parameters
    /// - `session_id`: ä¼šè¯å”¯ä¸€æ ‡è¯†
    /// - `session_id`: Unique session identifier
    /// - `message`: ç”¨æˆ·æ¶ˆæ¯
    /// - `message`: User message
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// let session_id = agent.create_session().await;
    /// let response = agent.chat_with_session(&session_id, "Hello").await?;
    /// ```
    pub async fn chat_with_session(
        &self,
        session_id: &str,
        message: impl Into<String>,
    ) -> LLMResult<String> {
        let message = message.into();

        // è·å–æ¨¡å‹åç§°
        // Get model name
        let model = self.provider.default_model();

        // è°ƒç”¨ before_chat é’©å­ï¼ˆå¸¦æ¨¡å‹åç§°ï¼‰
        // Call before_chat hook (with model name)
        let processed_message = if let Some(ref handler) = self.event_handler {
            match handler.before_chat_with_model(&message, model).await? {
                Some(msg) => msg,
                None => return Ok(String::new()),
            }
        } else {
            message
        };

        // è·å–ä¼šè¯
        // Get session
        let session = self.get_session_arc(session_id).await?;

        // å‘é€æ¶ˆæ¯
        // Send message
        let mut session_guard = session.write().await;
        let response = match session_guard.send(&processed_message).await {
            Ok(resp) => resp,
            Err(e) => {
                if let Some(ref handler) = self.event_handler
                    && let Some(fallback) = handler.on_error(&e).await?
                {
                    return Ok(fallback);
                }
                return Err(e);
            }
        };

        // è°ƒç”¨ after_chat é’©å­ï¼ˆå¸¦å…ƒæ•°æ®ï¼‰
        // Call after_chat hook (with metadata)
        let final_response = if let Some(ref handler) = self.event_handler {
            // ä»ä¼šè¯ä¸­è·å–å“åº”å…ƒæ•°æ®
            // Get response metadata from the session
            let metadata = session_guard.last_response_metadata();
            if let Some(meta) = metadata {
                match handler.after_chat_with_metadata(&response, meta).await? {
                    Some(resp) => resp,
                    None => response,
                }
            } else {
                // å›é€€åˆ°æ—§æ–¹æ³•ï¼ˆæ²¡æœ‰å…ƒæ•°æ®ï¼‰
                // Fall back to old method (no metadata)
                match handler.after_chat(&response).await? {
                    Some(resp) => resp,
                    None => response,
                }
            }
        } else {
            response
        };

        Ok(final_response)
    }

    /// ç®€å•é—®ç­”ï¼ˆä¸ä¿ç•™ä¸Šä¸‹æ–‡ï¼‰
    /// Simple Q&A (no context retained)
    pub async fn ask(&self, question: impl Into<String>) -> LLMResult<String> {
        let question = question.into();

        let mut builder = self.client.chat();

        // ä½¿ç”¨åŠ¨æ€ Prompt æ¨¡æ¿ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        // Use dynamic prompt template (if available)
        let mut system_prompt = self.config.system_prompt.clone();

        if let Some(ref plugin) = self.prompt_plugin
            && let Some(template) = plugin.get_current_template().await
        {
            // æ¸²æŸ“é»˜è®¤æ¨¡æ¿ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ å˜é‡ï¼‰
            // Render default template (variables can be added as needed)
            match template.render(&[]) {
                Ok(prompt) => system_prompt = Some(prompt),
                Err(_) => {
                    // å¦‚æœæ¸²æŸ“å¤±è´¥ï¼Œä½¿ç”¨å›é€€çš„ç³»ç»Ÿæç¤ºè¯
                    // If rendering fails, use fallback system prompt
                    system_prompt = self.config.system_prompt.clone();
                }
            }
        }

        // è®¾ç½®ç³»ç»Ÿæç¤ºè¯
        // Set system prompt
        if let Some(ref system) = system_prompt {
            builder = builder.system(system.clone());
        }

        if let Some(temp) = self.config.temperature {
            builder = builder.temperature(temp);
        }

        if let Some(tokens) = self.config.max_tokens {
            builder = builder.max_tokens(tokens);
        }

        builder = builder.user(question);

        // æ·»åŠ å·¥å…·
        // Add tools
        if let Some(ref executor) = self.tool_executor {
            let tools = if self.tools.is_empty() {
                executor.available_tools().await?
            } else {
                self.tools.clone()
            };

            if !tools.is_empty() {
                builder = builder.tools(tools);
            }

            builder = builder.with_tool_executor(executor.clone());
            let response = builder.send_with_tools().await?;
            return response
                .content()
                .map(|s| s.to_string())
                .ok_or_else(|| LLMError::Other("No content in response".to_string()));
        }

        let response = builder.send().await?;
        response
            .content()
            .map(|s| s.to_string())
            .ok_or_else(|| LLMError::Other("No content in response".to_string()))
    }

    /// è®¾ç½® Prompt åœºæ™¯
    /// Set prompt scenario
    pub async fn set_prompt_scenario(&self, scenario: impl Into<String>) {
        let scenario = scenario.into();

        if let Some(ref plugin) = self.prompt_plugin {
            plugin.set_active_scenario(&scenario).await;
        }
    }

    /// æ¸…ç©ºå¯¹è¯å†å²ï¼ˆå½“å‰æ´»åŠ¨ä¼šè¯ï¼‰
    /// Clear conversation history (for the current active session)
    pub async fn clear_history(&self) {
        let session_id = self.active_session_id.read().await.clone();
        let _ = self.clear_session_history(&session_id).await;
    }

    /// æ¸…ç©ºæŒ‡å®šä¼šè¯çš„å¯¹è¯å†å²
    /// Clear the conversation history of a specified session
    pub async fn clear_session_history(&self, session_id: &str) -> LLMResult<()> {
        let session = self.get_session_arc(session_id).await?;
        let mut session_guard = session.write().await;
        session_guard.clear();
        Ok(())
    }

    /// è·å–å¯¹è¯å†å²ï¼ˆå½“å‰æ´»åŠ¨ä¼šè¯ï¼‰
    /// Retrieve conversation history (for the current active session)
    pub async fn history(&self) -> Vec<ChatMessage> {
        let session_id = self.active_session_id.read().await.clone();
        self.get_session_history(&session_id)
            .await
            .unwrap_or_default()
    }

    /// è·å–æŒ‡å®šä¼šè¯çš„å¯¹è¯å†å²
    /// Retrieve the conversation history of a specified session
    pub async fn get_session_history(&self, session_id: &str) -> LLMResult<Vec<ChatMessage>> {
        let session = self.get_session_arc(session_id).await?;
        let session_guard = session.read().await;
        Ok(session_guard.messages().to_vec())
    }

    /// è®¾ç½®å·¥å…·
    /// Set up tools
    pub fn set_tools(&mut self, tools: Vec<Tool>, executor: Arc<dyn ToolExecutor>) {
        self.tools = tools;
        self.tool_executor = Some(executor);

        // æ›´æ–° session ä¸­çš„å·¥å…·
        // Update the tools within the session
        // æ³¨æ„ï¼šè¿™éœ€è¦é‡æ–°åˆ›å»º sessionï¼Œå› ä¸º with_tools æ¶ˆè€— self
        // Note: This requires session recreation as with_tools consumes self
    }

    /// è®¾ç½®äº‹ä»¶å¤„ç†å™¨
    /// Set up the event handler
    pub fn set_event_handler(&mut self, handler: Box<dyn LLMAgentEventHandler>) {
        self.event_handler = Some(handler);
    }

    /// å‘æ™ºèƒ½ä½“æ·»åŠ æ’ä»¶
    /// Add a plugin to the agent
    pub fn add_plugin<P: AgentPlugin + 'static>(&mut self, plugin: P) {
        self.plugins.push(Box::new(plugin));
    }

    /// å‘æ™ºèƒ½ä½“æ·»åŠ æ’ä»¶åˆ—è¡¨
    /// Add a list of plugins to the agent
    pub fn add_plugins(&mut self, plugins: Vec<Box<dyn AgentPlugin>>) {
        self.plugins.extend(plugins);
    }

    // ========================================================================
    // æµå¼å¯¹è¯æ–¹æ³•
    // Streaming Dialogue Methods
    // ========================================================================

    /// æµå¼é—®ç­”ï¼ˆä¸ä¿ç•™ä¸Šä¸‹æ–‡ï¼‰
    /// Streaming Q&A (without context retention)
    ///
    /// è¿”å›ä¸€ä¸ª Streamï¼Œæ¯æ¬¡ yield ä¸€ä¸ªæ–‡æœ¬ç‰‡æ®µ
    /// Returns a Stream that yields a text fragment each time
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// use futures::StreamExt;
    ///
    /// let mut stream = agent.ask_stream("Tell me a story").await?;
    /// while let Some(result) = stream.next().await {
    ///     match result {
    ///         Ok(text) => print!("{}", text),
    ///         Err(e) => einfo!("Error: {}", e),
    ///     }
    /// }
    /// ```
    pub async fn ask_stream(&self, question: impl Into<String>) -> LLMResult<TextStream> {
        let question = question.into();

        let mut builder = self.client.chat();

        if let Some(ref system) = self.config.system_prompt {
            builder = builder.system(system.clone());
        }

        if let Some(temp) = self.config.temperature {
            builder = builder.temperature(temp);
        }

        if let Some(tokens) = self.config.max_tokens {
            builder = builder.max_tokens(tokens);
        }

        builder = builder.user(question);

        // å‘é€æµå¼è¯·æ±‚
        // Send a streaming request
        let chunk_stream = builder.send_stream().await?;

        // è½¬æ¢ä¸ºçº¯æ–‡æœ¬æµ
        // Convert to a plain text stream
        Ok(Self::chunk_stream_to_text_stream(chunk_stream))
    }

    /// æµå¼å¤šè½®å¯¹è¯ï¼ˆä¿ç•™ä¸Šä¸‹æ–‡ï¼‰
    /// Streaming multi-turn dialogue (with context retention)
    ///
    /// æ³¨æ„ï¼šæµå¼å¯¹è¯ä¼šåœ¨æ”¶åˆ°å®Œæ•´å“åº”åæ›´æ–°å†å²è®°å½•
    /// Note: Streaming dialogue updates history after receiving full response
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// use futures::StreamExt;
    ///
    /// let mut stream = agent.chat_stream("Hello!").await?;
    /// let mut full_response = String::new();
    /// while let Some(result) = stream.next().await {
    ///     match result {
    ///         Ok(text) => {
    ///             print!("{}", text);
    ///             full_response.push_str(&text);
    ///         }
    ///         Err(e) => einfo!("Error: {}", e),
    ///     }
    /// }
    /// info!();
    /// ```
    pub async fn chat_stream(&self, message: impl Into<String>) -> LLMResult<TextStream> {
        let session_id = self.active_session_id.read().await.clone();
        self.chat_stream_with_session(&session_id, message).await
    }

    /// ä½¿ç”¨æŒ‡å®šä¼šè¯è¿›è¡Œæµå¼å¤šè½®å¯¹è¯
    /// Use a specified session for streaming multi-turn dialogue
    ///
    /// # å‚æ•°
    /// # Parameters
    /// - `session_id`: ä¼šè¯å”¯ä¸€æ ‡è¯†
    /// - `session_id`: Unique identifier for the session
    /// - `message`: ç”¨æˆ·æ¶ˆæ¯
    /// - `message`: User message
    pub async fn chat_stream_with_session(
        &self,
        session_id: &str,
        message: impl Into<String>,
    ) -> LLMResult<TextStream> {
        let message = message.into();

        // è·å–æ¨¡å‹åç§°
        // Retrieve the model name
        let model = self.provider.default_model();

        // è°ƒç”¨ before_chat é’©å­ï¼ˆå¸¦æ¨¡å‹åç§°ï¼‰
        // Invoke before_chat hook (with model name)
        let processed_message = if let Some(ref handler) = self.event_handler {
            match handler.before_chat_with_model(&message, model).await? {
                Some(msg) => msg,
                None => return Ok(Box::pin(futures::stream::empty())),
            }
        } else {
            message
        };

        // è·å–ä¼šè¯
        // Retrieve the session
        let session = self.get_session_arc(session_id).await?;

        // è·å–å½“å‰å†å²
        // Retrieve current history
        let history = {
            let session_guard = session.read().await;
            session_guard.messages().to_vec()
        };

        // æ„å»ºè¯·æ±‚
        // Construct the request
        let mut builder = self.client.chat();

        if let Some(ref system) = self.config.system_prompt {
            builder = builder.system(system.clone());
        }

        if let Some(temp) = self.config.temperature {
            builder = builder.temperature(temp);
        }

        if let Some(tokens) = self.config.max_tokens {
            builder = builder.max_tokens(tokens);
        }

        // æ·»åŠ å†å²æ¶ˆæ¯
        // Add history messages
        builder = builder.messages(history);
        builder = builder.user(processed_message.clone());

        // å‘é€æµå¼è¯·æ±‚
        // Send a streaming request
        let chunk_stream = builder.send_stream().await?;

        // åœ¨æµå¼å¤„ç†å‰ï¼Œå…ˆæ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        // Add user message to history before stream processing
        {
            let mut session_guard = session.write().await;
            session_guard
                .messages_mut()
                .push(ChatMessage::user(&processed_message));
        }

        // åˆ›å»ºä¸€ä¸ªåŒ…è£…æµï¼Œåœ¨å®Œæˆæ—¶æ›´æ–°å†å²å¹¶è°ƒç”¨äº‹ä»¶å¤„ç†
        // Create a wrapped stream to update history and call events on completion
        let event_handler = self.event_handler.clone().map(Arc::new);
        let wrapped_stream =
            Self::create_history_updating_stream(chunk_stream, session, event_handler);

        Ok(wrapped_stream)
    }

    /// è·å–åŸå§‹æµå¼å“åº”å—ï¼ˆåŒ…å«å®Œæ•´ä¿¡æ¯ï¼‰
    /// Retrieve raw streaming response chunks (including full info)
    ///
    /// å¦‚æœéœ€è¦è®¿é—®å·¥å…·è°ƒç”¨ç­‰è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨æ­¤æ–¹æ³•
    /// Use this method if detailed info like tool calls is required
    pub async fn ask_stream_raw(&self, question: impl Into<String>) -> LLMResult<ChatStream> {
        let question = question.into();

        let mut builder = self.client.chat();

        if let Some(ref system) = self.config.system_prompt {
            builder = builder.system(system.clone());
        }

        if let Some(temp) = self.config.temperature {
            builder = builder.temperature(temp);
        }

        if let Some(tokens) = self.config.max_tokens {
            builder = builder.max_tokens(tokens);
        }

        builder = builder.user(question);

        builder.send_stream().await
    }

    /// æµå¼å¯¹è¯å¹¶æ”¶é›†å®Œæ•´å“åº”ï¼ˆä½¿ç”¨å½“å‰æ´»åŠ¨ä¼šè¯ï¼‰
    /// Stream dialogue and collect full response (using active session)
    ///
    /// åŒæ—¶è¿”å›æµå’Œä¸€ä¸ª channel ç”¨äºè·å–å®Œæ•´å“åº”
    /// Returns both the stream and a channel to retrieve the full response
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// use futures::StreamExt;
    ///
    /// let (mut stream, full_response_rx) = agent.chat_stream_with_full("Hi").await?;
    ///
    /// while let Some(result) = stream.next().await {
    ///     if let Ok(text) = result {
    ///         print!("{}", text);
    ///     }
    /// }
    ///
    /// let full_response = full_response_rx.await?;
    /// info!("\nFull response: {}", full_response);
    /// ```
    pub async fn chat_stream_with_full(
        &self,
        message: impl Into<String>,
    ) -> LLMResult<(TextStream, tokio::sync::oneshot::Receiver<String>)> {
        let session_id = self.active_session_id.read().await.clone();
        self.chat_stream_with_full_session(&session_id, message)
            .await
    }

    /// ä½¿ç”¨æŒ‡å®šä¼šè¯è¿›è¡Œæµå¼å¯¹è¯å¹¶æ”¶é›†å®Œæ•´å“åº”
    /// Use a specified session for streaming and full response collection
    ///
    /// # å‚æ•°
    /// # Parameters
    /// - `session_id`: ä¼šè¯å”¯ä¸€æ ‡è¯†
    /// - `session_id`: Unique identifier for the session
    /// - `message`: ç”¨æˆ·æ¶ˆæ¯
    /// - `message`: User message
    pub async fn chat_stream_with_full_session(
        &self,
        session_id: &str,
        message: impl Into<String>,
    ) -> LLMResult<(TextStream, tokio::sync::oneshot::Receiver<String>)> {
        let message = message.into();

        // è·å–æ¨¡å‹åç§°
        // Retrieve the model name
        let model = self.provider.default_model();

        // è°ƒç”¨ before_chat é’©å­ï¼ˆå¸¦æ¨¡å‹åç§°ï¼‰
        // Invoke before_chat hook (with model name)
        let processed_message = if let Some(ref handler) = self.event_handler {
            match handler.before_chat_with_model(&message, model).await? {
                Some(msg) => msg,
                None => {
                    let (tx, rx) = tokio::sync::oneshot::channel();
                    let _ = tx.send(String::new());
                    return Ok((Box::pin(futures::stream::empty()), rx));
                }
            }
        } else {
            message
        };

        // è·å–ä¼šè¯
        // Retrieve the session
        let session = self.get_session_arc(session_id).await?;

        // è·å–å½“å‰å†å²
        // Retrieve current history
        let history = {
            let session_guard = session.read().await;
            session_guard.messages().to_vec()
        };

        // æ„å»ºè¯·æ±‚
        // Construct the request
        let mut builder = self.client.chat();

        if let Some(ref system) = self.config.system_prompt {
            builder = builder.system(system.clone());
        }

        if let Some(temp) = self.config.temperature {
            builder = builder.temperature(temp);
        }

        if let Some(tokens) = self.config.max_tokens {
            builder = builder.max_tokens(tokens);
        }

        builder = builder.messages(history);
        builder = builder.user(processed_message.clone());

        let chunk_stream = builder.send_stream().await?;

        // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        // Add user message to history
        {
            let mut session_guard = session.write().await;
            session_guard
                .messages_mut()
                .push(ChatMessage::user(&processed_message));
        }

        // åˆ›å»º channel ç”¨äºä¼ é€’å®Œæ•´å“åº”
        // Create a channel to pass the full response
        let (tx, rx) = tokio::sync::oneshot::channel();

        // åˆ›å»ºæ”¶é›†å®Œæ•´å“åº”çš„æµ
        // Create a stream that collects the full response
        let event_handler = self.event_handler.clone().map(Arc::new);
        let wrapped_stream =
            Self::create_collecting_stream(chunk_stream, session, tx, event_handler);

        Ok((wrapped_stream, rx))
    }

    // ========================================================================
    // å†…éƒ¨è¾…åŠ©æ–¹æ³•
    // Internal Helper Methods
    // ========================================================================

    /// å°† chunk stream è½¬æ¢ä¸ºçº¯æ–‡æœ¬ stream
    /// Convert chunk stream into a plain text stream
    fn chunk_stream_to_text_stream(chunk_stream: ChatStream) -> TextStream {
        use futures::StreamExt;

        let text_stream = chunk_stream.filter_map(|result| async move {
            match result {
                Ok(chunk) => {
                    // æå–æ–‡æœ¬å†…å®¹
                    // Extract text content
                    if let Some(choice) = chunk.choices.first()
                        && let Some(ref content) = choice.delta.content
                        && !content.is_empty()
                    {
                        return Some(Ok(content.clone()));
                    }
                    None
                }
                Err(e) => Some(Err(e)),
            }
        });

        Box::pin(text_stream)
    }

    /// åˆ›å»ºæ›´æ–°å†å²çš„æµ
    /// Create a stream that updates conversation history
    fn create_history_updating_stream(
        chunk_stream: ChatStream,
        session: Arc<RwLock<ChatSession>>,
        event_handler: Option<Arc<Box<dyn LLMAgentEventHandler>>>,
    ) -> TextStream {
        use super::types::LLMResponseMetadata;

        let collected = Arc::new(tokio::sync::Mutex::new(String::new()));
        let collected_clone = collected.clone();
        let event_handler_clone = event_handler.clone();
        let metadata_collected = Arc::new(tokio::sync::Mutex::new(None::<LLMResponseMetadata>));
        let metadata_collected_clone = metadata_collected.clone();

        let stream = chunk_stream.filter_map(move |result| {
            let collected = collected.clone();
            let event_handler = event_handler.clone();
            let metadata_collected = metadata_collected.clone();
            async move {
                match result {
                    Ok(chunk) => {
                        if let Some(choice) = chunk.choices.first() {
                            if choice.finish_reason.is_some() {
                                // æœ€åä¸€ä¸ªå—åŒ…å« usage æ•°æ®ï¼Œä¿å­˜å…ƒæ•°æ®
                                // The last block contains usage data; save the metadata
                                let metadata = LLMResponseMetadata::from(&chunk);
                                *metadata_collected.lock().await = Some(metadata);
                                return None;
                            }
                            if let Some(ref content) = choice.delta.content
                                && !content.is_empty()
                            {
                                let mut collected = collected.lock().await;
                                collected.push_str(content);
                                return Some(Ok(content.clone()));
                            }
                        }
                        None
                    }
                    Err(e) => {
                        if let Some(handler) = event_handler {
                            let _ = handler.on_error(&e).await;
                        }
                        Some(Err(e))
                    }
                }
            }
        });

        let stream = stream
            .chain(futures::stream::once(async move {
                let full_response = collected_clone.lock().await.clone();
                let metadata = metadata_collected_clone.lock().await.clone();
                if !full_response.is_empty() {
                    let mut session = session.write().await;
                    session
                        .messages_mut()
                        .push(ChatMessage::assistant(&full_response));

                    // æ»‘åŠ¨çª—å£ï¼šè£å‰ªå†å²æ¶ˆæ¯ä»¥ä¿æŒå›ºå®šå¤§å°
                    // Sliding window: trim historical messages to maintain a fixed size
                    let window_size = session.context_window_size();
                    if window_size.is_some() {
                        let current_messages = session.messages().to_vec();
                        *session.messages_mut() = ChatSession::apply_sliding_window_static(
                            &current_messages,
                            window_size,
                        );
                    }

                    if let Some(handler) = event_handler_clone {
                        if let Some(meta) = &metadata {
                            let _ = handler.after_chat_with_metadata(&full_response, meta).await;
                        } else {
                            let _ = handler.after_chat(&full_response).await;
                        }
                    }
                }
                Err(LLMError::Other("__stream_end__".to_string()))
            }))
            .filter_map(|result| async move {
                match result {
                    Ok(s) => Some(Ok(s)),
                    Err(e) if e.to_string() == "__stream_end__" => None,
                    Err(e) => Some(Err(e)),
                }
            });

        Box::pin(stream)
    }

    /// åˆ›å»ºæ”¶é›†å®Œæ•´å“åº”çš„æµ
    /// Create a stream to collect the full response
    fn create_collecting_stream(
        chunk_stream: ChatStream,
        session: Arc<RwLock<ChatSession>>,
        tx: tokio::sync::oneshot::Sender<String>,
        event_handler: Option<Arc<Box<dyn LLMAgentEventHandler>>>,
    ) -> TextStream {
        use super::types::LLMResponseMetadata;
        use futures::StreamExt;

        let collected = Arc::new(tokio::sync::Mutex::new(String::new()));
        let collected_clone = collected.clone();
        let event_handler_clone = event_handler.clone();
        let metadata_collected = Arc::new(tokio::sync::Mutex::new(None::<LLMResponseMetadata>));
        let metadata_collected_clone = metadata_collected.clone();

        let stream = chunk_stream.filter_map(move |result| {
            let collected = collected.clone();
            let event_handler = event_handler.clone();
            let metadata_collected = metadata_collected.clone();
            async move {
                match result {
                    Ok(chunk) => {
                        if let Some(choice) = chunk.choices.first() {
                            if choice.finish_reason.is_some() {
                                // æœ€åä¸€ä¸ªå—åŒ…å« usage æ•°æ®ï¼Œä¿å­˜å…ƒæ•°æ®
                                // The last block contains usage data; save the metadata
                                let metadata = LLMResponseMetadata::from(&chunk);
                                *metadata_collected.lock().await = Some(metadata);
                                return None;
                            }
                            if let Some(ref content) = choice.delta.content
                                && !content.is_empty()
                            {
                                let mut collected = collected.lock().await;
                                collected.push_str(content);
                                return Some(Ok(content.clone()));
                            }
                        }
                        None
                    }
                    Err(e) => {
                        if let Some(handler) = event_handler {
                            let _ = handler.on_error(&e).await;
                        }
                        Some(Err(e))
                    }
                }
            }
        });

        // åœ¨æµç»“æŸåæ›´æ–°å†å²å¹¶å‘é€å®Œæ•´å“åº”
        // Update history and send full response after stream ends
        let stream = stream
            .chain(futures::stream::once(async move {
                let full_response = collected_clone.lock().await.clone();
                let mut processed_response = full_response.clone();
                let metadata = metadata_collected_clone.lock().await.clone();

                if !full_response.is_empty() {
                    let mut session = session.write().await;
                    session
                        .messages_mut()
                        .push(ChatMessage::assistant(&processed_response));

                    // æ»‘åŠ¨çª—å£ï¼šè£å‰ªå†å²æ¶ˆæ¯ä»¥ä¿æŒå›ºå®šå¤§å°
                    // Sliding window: trim historical messages to maintain a fixed size
                    let window_size = session.context_window_size();
                    if window_size.is_some() {
                        let current_messages = session.messages().to_vec();
                        *session.messages_mut() = ChatSession::apply_sliding_window_static(
                            &current_messages,
                            window_size,
                        );
                    }

                    // è°ƒç”¨ after_chat é’©å­ï¼ˆå¸¦å…ƒæ•°æ®ï¼‰
                    // Invoke after_chat hook (with metadata)
                    if let Some(handler) = event_handler_clone {
                        if let Some(meta) = &metadata {
                            if let Ok(Some(resp)) = handler
                                .after_chat_with_metadata(&processed_response, meta)
                                .await
                            {
                                processed_response = resp;
                            }
                        } else if let Ok(Some(resp)) = handler.after_chat(&processed_response).await
                        {
                            processed_response = resp;
                        }
                    }
                }

                let _ = tx.send(processed_response);

                Err(LLMError::Other("__stream_end__".to_string()))
            }))
            .filter_map(|result| async move {
                match result {
                    Ok(s) => Some(Ok(s)),
                    Err(e) if e.to_string() == "__stream_end__" => None,
                    Err(e) => Some(Err(e)),
                }
            });

        Box::pin(stream)
    }
}

/// LLM Agent æ„å»ºå™¨
/// LLM Agent Builder
pub struct LLMAgentBuilder {
    agent_id: String,
    name: Option<String>,
    provider: Option<Arc<dyn LLMProvider>>,
    system_prompt: Option<String>,
    temperature: Option<f32>,
    max_tokens: Option<u32>,
    tools: Vec<Tool>,
    tool_executor: Option<Arc<dyn ToolExecutor>>,
    event_handler: Option<Box<dyn LLMAgentEventHandler>>,
    plugins: Vec<Box<dyn AgentPlugin>>,
    custom_config: HashMap<String, String>,
    prompt_plugin: Option<Box<dyn prompt::PromptTemplatePlugin>>,
    session_id: Option<String>,
    user_id: Option<String>,
    tenant_id: Option<String>,
    context_window_size: Option<usize>,
    /// æŒä¹…åŒ–å­˜å‚¨ï¼ˆç”¨äºä»æ•°æ®åº“åŠ è½½å†å²ä¼šè¯ï¼‰
    /// Persistent storage (used for loading historical sessions from database)
    message_store: Option<Arc<dyn crate::persistence::MessageStore + Send + Sync>>,
    session_store: Option<Arc<dyn crate::persistence::SessionStore + Send + Sync>>,
    persistence_user_id: Option<uuid::Uuid>,
    persistence_tenant_id: Option<uuid::Uuid>,
    persistence_agent_id: Option<uuid::Uuid>,
}

impl Default for LLMAgentBuilder {
    fn default() -> Self {
        Self::new()
    }
}

impl LLMAgentBuilder {
    /// åˆ›å»ºæ–°çš„æ„å»ºå™¨
    /// Create a new builder
    pub fn new() -> Self {
        Self {
            agent_id: uuid::Uuid::now_v7().to_string(),
            name: None,
            provider: None,
            system_prompt: None,
            temperature: None,
            max_tokens: None,
            tools: Vec::new(),
            tool_executor: None,
            event_handler: None,
            plugins: Vec::new(),
            custom_config: HashMap::new(),
            prompt_plugin: None,
            session_id: None,
            user_id: None,
            tenant_id: None,
            context_window_size: None,
            message_store: None,
            session_store: None,
            persistence_user_id: None,
            persistence_tenant_id: None,
            persistence_agent_id: None,
        }
    }

    /// è®¾ç½®id
    /// Set the ID
    pub fn with_id(mut self, id: impl Into<String>) -> Self {
        self.agent_id = id.into();
        self
    }

    /// è®¾ç½®åç§°
    /// Set the name
    pub fn with_name(mut self, name: impl Into<String>) -> Self {
        self.name = Some(name.into());
        self
    }

    /// è®¾ç½® LLM Provider
    /// Set the LLM Provider
    pub fn with_provider(mut self, provider: Arc<dyn LLMProvider>) -> Self {
        self.provider = Some(provider);
        self
    }

    /// è®¾ç½®ç³»ç»Ÿæç¤ºè¯
    /// Set the system prompt
    pub fn with_system_prompt(mut self, prompt: impl Into<String>) -> Self {
        self.system_prompt = Some(prompt.into());
        self
    }

    /// è®¾ç½®æ¸©åº¦
    /// Set the temperature
    pub fn with_temperature(mut self, temperature: f32) -> Self {
        self.temperature = Some(temperature);
        self
    }

    /// è®¾ç½®æœ€å¤§ token æ•°
    /// Set the maximum number of tokens
    pub fn with_max_tokens(mut self, max_tokens: u32) -> Self {
        self.max_tokens = Some(max_tokens);
        self
    }

    /// æ·»åŠ å·¥å…·
    /// Add a tool
    pub fn with_tool(mut self, tool: Tool) -> Self {
        self.tools.push(tool);
        self
    }

    /// è®¾ç½®å·¥å…·åˆ—è¡¨
    /// Set the tool list
    pub fn with_tools(mut self, tools: Vec<Tool>) -> Self {
        self.tools = tools;
        self
    }

    /// è®¾ç½®å·¥å…·æ‰§è¡Œå™¨
    /// Set the tool executor
    pub fn with_tool_executor(mut self, executor: Arc<dyn ToolExecutor>) -> Self {
        self.tool_executor = Some(executor);
        self
    }

    /// è®¾ç½®äº‹ä»¶å¤„ç†å™¨
    /// Set the event handler
    pub fn with_event_handler(mut self, handler: Box<dyn LLMAgentEventHandler>) -> Self {
        self.event_handler = Some(handler);
        self
    }

    /// æ·»åŠ æ’ä»¶
    /// Add a plugin
    pub fn with_plugin(mut self, plugin: impl AgentPlugin + 'static) -> Self {
        self.plugins.push(Box::new(plugin));
        self
    }

    /// æ·»åŠ æ’ä»¶åˆ—è¡¨
    /// Add a list of plugins
    pub fn with_plugins(mut self, plugins: Vec<Box<dyn AgentPlugin>>) -> Self {
        self.plugins.extend(plugins);
        self
    }

    /// æ·»åŠ æŒä¹…åŒ–æ’ä»¶ï¼ˆä¾¿æ·æ–¹æ³•ï¼‰
    /// Add persistence plugin (convenience method)
    ///
    /// æŒä¹…åŒ–æ’ä»¶å®ç°äº† AgentPlugin traitï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸€ä¸ª LLMAgentEventHandlerï¼Œ
    /// The persistence plugin implements AgentPlugin and is also an LLMAgentEventHandler,
    /// ä¼šè‡ªåŠ¨æ³¨å†Œåˆ° agent çš„æ’ä»¶åˆ—è¡¨å’Œäº‹ä»¶å¤„ç†å™¨ä¸­ã€‚
    /// automatically registering into the agent's plugin list and event handler.
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// use mofa_sdk::persistence::{PersistencePlugin, PostgresStore};
    /// use mofa_sdk::llm::LLMAgentBuilder;
    /// use std::sync::Arc;
    /// use uuid::Uuid;
    ///
    /// # async fn example() -> GlobalResult<()> {
    /// let store = Arc::new(PostgresStore::connect("postgres://localhost/mofa").await?);
    /// let user_id = Uuid::now_v7();
    /// let tenant_id = Uuid::now_v7();
    /// let agent_id = Uuid::now_v7();
    /// let session_id = Uuid::now_v7();
    ///
    /// let plugin = PersistencePlugin::new(
    ///     "persistence-plugin",
    ///     store,
    ///     user_id,
    ///     tenant_id,
    ///     agent_id,
    ///     session_id,
    /// );
    ///
    /// let agent = LLMAgentBuilder::new()
    ///     .with_id("my-agent")
    ///     .with_persistence_plugin(plugin)
    ///     .build_async()
    ///     .await;
    /// # Ok(())
    /// # }
    /// ```
    pub fn with_persistence_plugin(
        mut self,
        plugin: crate::persistence::PersistencePlugin,
    ) -> Self {
        self.message_store = Some(plugin.message_store());
        self.session_store = plugin.session_store();
        self.persistence_user_id = Some(plugin.user_id());
        self.persistence_tenant_id = Some(plugin.tenant_id());
        self.persistence_agent_id = Some(plugin.agent_id());

        // å°†æŒä¹…åŒ–æ’ä»¶æ·»åŠ åˆ°æ’ä»¶åˆ—è¡¨
        // Add the persistence plugin to the plugin list
        // åŒæ—¶ä½œä¸ºäº‹ä»¶å¤„ç†å™¨
        // Also serves as an event handler
        let plugin_box: Box<dyn AgentPlugin> = Box::new(plugin.clone());
        let event_handler: Box<dyn LLMAgentEventHandler> = Box::new(plugin);
        self.plugins.push(plugin_box);
        self.event_handler = Some(event_handler);
        self
    }

    /// è®¾ç½® Prompt æ¨¡æ¿æ’ä»¶
    /// Set the Prompt template plugin
    pub fn with_prompt_plugin(
        mut self,
        plugin: impl prompt::PromptTemplatePlugin + 'static,
    ) -> Self {
        self.prompt_plugin = Some(Box::new(plugin));
        self
    }

    /// è®¾ç½®æ”¯æŒçƒ­é‡è½½çš„ Prompt æ¨¡æ¿æ’ä»¶
    /// Set a hot-reloadable Prompt template plugin
    pub fn with_hot_reload_prompt_plugin(
        mut self,
        plugin: prompt::HotReloadableRhaiPromptPlugin,
    ) -> Self {
        self.prompt_plugin = Some(Box::new(plugin));
        self
    }

    /// æ·»åŠ è‡ªå®šä¹‰é…ç½®
    /// Add custom configuration
    pub fn with_config(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.custom_config.insert(key.into(), value.into());
        self
    }

    /// è®¾ç½®åˆå§‹ä¼šè¯ ID
    /// Set the initial session ID
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// let agent = LLMAgentBuilder::new()
    ///     .with_id("my-agent")
    ///     .with_initial_session_id("user-session-001")
    ///     .build();
    /// ```
    pub fn with_session_id(mut self, session_id: impl Into<String>) -> Self {
        self.session_id = Some(session_id.into());
        self
    }

    /// è®¾ç½®ç”¨æˆ· ID
    /// Set the user ID
    ///
    /// ç”¨äºæ•°æ®åº“æŒä¹…åŒ–å’Œå¤šç”¨æˆ·åœºæ™¯çš„æ¶ˆæ¯éš”ç¦»ã€‚
    /// Used for database persistence and message isolation in multi-user scenarios.
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// let agent = LLMAgentBuilder::new()
    ///     .with_id("my-agent")
    ///     .with_user("user-123")
    ///     .build();
    /// ```
    pub fn with_user(mut self, user_id: impl Into<String>) -> Self {
        self.user_id = Some(user_id.into());
        self
    }

    /// è®¾ç½®ç§Ÿæˆ· ID
    /// Set the tenant ID
    ///
    /// ç”¨äºå¤šç§Ÿæˆ·æ”¯æŒï¼Œå®ç°ä¸åŒç§Ÿæˆ·çš„æ•°æ®éš”ç¦»ã€‚
    /// Used for multi-tenant support to achieve data isolation between tenants.
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// let agent = LLMAgentBuilder::new()
    ///     .with_id("my-agent")
    ///     .with_tenant("tenant-abc")
    ///     .build();
    /// ```
    pub fn with_tenant(mut self, tenant_id: impl Into<String>) -> Self {
        self.tenant_id = Some(tenant_id.into());
        self
    }

    /// è®¾ç½®ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆæ»‘åŠ¨çª—å£ï¼‰
    /// Set context window size (sliding window)
    ///
    /// ç”¨äºæ»‘åŠ¨çª—å£æ¶ˆæ¯ç®¡ç†ï¼ŒæŒ‡å®šä¿ç•™çš„æœ€å¤§å¯¹è¯è½®æ•°ã€‚
    /// Used for sliding window management, specifying the max conversation rounds to keep.
    /// å½“æ¶ˆæ¯å†å²è¶…è¿‡æ­¤å¤§å°æ—¶ï¼Œä¼šè‡ªåŠ¨è£å‰ªè¾ƒæ—©çš„æ¶ˆæ¯ã€‚
    /// Older messages are automatically trimmed when history exceeds this size.
    ///
    /// # å‚æ•°
    /// # Parameters
    /// - `size`: ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆå•ä½ï¼šè½®æ•°ï¼Œroundsï¼‰
    /// - `size`: Context window size (unit: rounds)
    ///
    /// # æ³¨æ„
    /// # Note
    /// - å•ä½æ˜¯**è½®æ•°**ï¼ˆroundsï¼‰ï¼Œä¸æ˜¯ token æ•°é‡
    /// - The unit is **rounds**, not token count
    /// - æ¯è½®å¯¹è¯ â‰ˆ 1 ä¸ªç”¨æˆ·æ¶ˆæ¯ + 1 ä¸ªåŠ©æ‰‹å“åº”
    /// - Each round â‰ˆ 1 user message + 1 assistant response
    /// - ç³»ç»Ÿæ¶ˆæ¯å§‹ç»ˆä¿ç•™ï¼Œä¸è®¡å…¥è½®æ•°é™åˆ¶
    /// - System messages are always kept and do not count toward the round limit
    /// - ä»æ•°æ®åº“åŠ è½½æ¶ˆæ¯æ—¶ä¹Ÿä¼šåº”ç”¨æ­¤é™åˆ¶
    /// - This limit is also applied when loading messages from the database
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// let agent = LLMAgentBuilder::new()
    ///     .with_id("my-agent")
    ///     .with_sliding_window(10)  // åªä¿ç•™æœ€è¿‘ 10 è½®å¯¹è¯
    ///     .build();
    /// ```
    pub fn with_sliding_window(mut self, size: usize) -> Self {
        self.context_window_size = Some(size);
        self
    }

    /// ä»ç¯å¢ƒå˜é‡åˆ›å»ºåŸºç¡€é…ç½®
    /// Create basic configuration from environment variables
    ///
    /// è‡ªåŠ¨é…ç½®ï¼š
    /// Automatic configuration:
    /// - OpenAI Providerï¼ˆä» OPENAI_API_KEYï¼‰
    /// - OpenAI Provider (via OPENAI_API_KEY)
    /// - é»˜è®¤ temperature (0.7) å’Œ max_tokens (4096)
    /// - Default temperature (0.7) and max_tokens (4096)
    ///
    /// # ç¯å¢ƒå˜é‡
    /// # Environment Variables
    /// - OPENAI_API_KEY: OpenAI API å¯†é’¥ï¼ˆå¿…éœ€ï¼‰
    /// - OPENAI_API_KEY: OpenAI API key (required)
    /// - OPENAI_BASE_URL: å¯é€‰çš„ API åŸºç¡€ URL
    /// - OPENAI_BASE_URL: Optional API base URL
    /// - OPENAI_MODEL: å¯é€‰çš„é»˜è®¤æ¨¡å‹
    /// - OPENAI_MODEL: Optional default model
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// use mofa_sdk::llm::LLMAgentBuilder;
    ///
    /// let agent = LLMAgentBuilder::from_env()?
    ///     .with_system_prompt("You are a helpful assistant.")
    ///     .build();
    /// ```
    pub fn from_env() -> LLMResult<Self> {
        use super::openai::{OpenAIConfig, OpenAIProvider};

        let api_key = std::env::var("OPENAI_API_KEY").map_err(|_| {
            LLMError::ConfigError("OPENAI_API_KEY environment variable not set".to_string())
        })?;

        let mut config = OpenAIConfig::new(api_key);

        if let Ok(base_url) = std::env::var("OPENAI_BASE_URL") {
            config = config.with_base_url(&base_url);
        }

        if let Ok(model) = std::env::var("OPENAI_MODEL") {
            config = config.with_model(&model);
        }

        Ok(Self::new()
            .with_provider(Arc::new(OpenAIProvider::with_config(config)))
            .with_temperature(0.7)
            .with_max_tokens(4096))
    }

    /// æ„å»º LLM Agent
    /// Build the LLM Agent
    ///
    /// # Panics
    /// å¦‚æœæœªè®¾ç½® provider åˆ™ panic
    /// Panics if the provider is not set
    #[must_use]
    pub fn build(self) -> LLMAgent {
        let provider = self
            .provider
            .expect("LLM provider must be set before building");

        let config = LLMAgentConfig {
            agent_id: self.agent_id.clone(),
            name: self.name.unwrap_or_else(|| self.agent_id.clone()),
            system_prompt: self.system_prompt,
            temperature: self.temperature,
            max_tokens: self.max_tokens,
            custom_config: self.custom_config,
            user_id: self.user_id,
            tenant_id: self.tenant_id,
            context_window_size: self.context_window_size,
        };

        let mut agent = LLMAgent::with_initial_session(config, provider, self.session_id);

        // è®¾ç½®Promptæ¨¡æ¿æ’ä»¶
        // Set Prompt template plugin
        agent.prompt_plugin = self.prompt_plugin;

        if let Some(executor) = self.tool_executor {
            agent.set_tools(self.tools, executor);
        }

        if let Some(handler) = self.event_handler {
            agent.set_event_handler(handler);
        }

        // å¤„ç†æ’ä»¶åˆ—è¡¨ï¼šæå– TTS æ’ä»¶
        // Process plugin list: extract the TTS plugin
        let mut plugins = self.plugins;
        let mut tts_plugin = None;

        // æŸ¥æ‰¾å¹¶æå– TTS æ’ä»¶
        // Find and extract the TTS plugin
        for i in (0..plugins.len()).rev() {
            if plugins[i].as_any().is::<mofa_plugins::tts::TTSPlugin>() {
                // ä½¿ç”¨ Any::downcast_ref æ£€æŸ¥ç±»å‹
                // Check type using Any::downcast_ref
                // ç”±äºæˆ‘ä»¬éœ€è¦è·å–æ‰€æœ‰æƒï¼Œè¿™é‡Œä½¿ç”¨ is æ£€æŸ¥åç§»é™¤
                // Since ownership is needed, remove after checking with 'is'
                let plugin = plugins.remove(i);
                // å°è¯• downcast
                // Attempt downcast
                if let Ok(tts) = plugin.into_any().downcast::<mofa_plugins::tts::TTSPlugin>() {
                    tts_plugin = Some(Arc::new(Mutex::new(*tts)));
                }
            }
        }

        // æ·»åŠ å‰©ä½™æ’ä»¶
        // Add remaining plugins
        agent.add_plugins(plugins);

        // è®¾ç½® TTS æ’ä»¶
        // Set TTS plugin
        agent.tts_plugin = tts_plugin;

        agent
    }

    /// å°è¯•æ„å»º LLM Agent
    /// Attempt to build the LLM Agent
    ///
    /// å¦‚æœæœªè®¾ç½® provider åˆ™è¿”å›é”™è¯¯
    /// Returns an error if the provider is not set
    pub fn try_build(self) -> LLMResult<LLMAgent> {
        let provider = self
            .provider
            .ok_or_else(|| LLMError::ConfigError("LLM provider not set".to_string()))?;

        let config = LLMAgentConfig {
            agent_id: self.agent_id.clone(),
            name: self.name.unwrap_or_else(|| self.agent_id.clone()),
            system_prompt: self.system_prompt,
            temperature: self.temperature,
            max_tokens: self.max_tokens,
            custom_config: self.custom_config,
            user_id: self.user_id,
            tenant_id: self.tenant_id,
            context_window_size: self.context_window_size,
        };

        let mut agent = LLMAgent::with_initial_session(config, provider, self.session_id);

        if let Some(executor) = self.tool_executor {
            agent.set_tools(self.tools, executor);
        }

        if let Some(handler) = self.event_handler {
            agent.set_event_handler(handler);
        }

        // å¤„ç†æ’ä»¶åˆ—è¡¨ï¼šæå– TTS æ’ä»¶
        // Process plugin list: extract the TTS plugin
        let mut plugins = self.plugins;
        let mut tts_plugin = None;

        // æŸ¥æ‰¾å¹¶æå– TTS æ’ä»¶
        // Find and extract the TTS plugin
        for i in (0..plugins.len()).rev() {
            if plugins[i].as_any().is::<mofa_plugins::tts::TTSPlugin>() {
                // ä½¿ç”¨ Any::downcast_ref æ£€æŸ¥ç±»å‹
                // Check type using Any::downcast_ref
                // ç”±äºæˆ‘ä»¬éœ€è¦è·å–æ‰€æœ‰æƒï¼Œè¿™é‡Œä½¿ç”¨ is æ£€æŸ¥åç§»é™¤
                // Since ownership is needed, remove after checking with 'is'
                let plugin = plugins.remove(i);
                // å°è¯• downcast
                // Attempt downcast
                if let Ok(tts) = plugin.into_any().downcast::<mofa_plugins::tts::TTSPlugin>() {
                    tts_plugin = Some(Arc::new(Mutex::new(*tts)));
                }
            }
        }

        // æ·»åŠ å‰©ä½™æ’ä»¶
        // Add remaining plugins
        agent.add_plugins(plugins);

        // è®¾ç½® TTS æ’ä»¶
        // Set TTS plugin
        agent.tts_plugin = tts_plugin;

        Ok(agent)
    }

    /// å¼‚æ­¥æ„å»º LLM Agentï¼ˆæ”¯æŒä»æ•°æ®åº“åŠ è½½ä¼šè¯ï¼‰
    /// Asynchronously build LLM Agent (supports loading sessions from DB)
    ///
    /// ä½¿ç”¨æŒä¹…åŒ–æ’ä»¶åŠ è½½ä¼šè¯å†å²ã€‚
    /// Use the persistence plugin to load conversation history.
    ///
    /// # ç¤ºä¾‹ï¼ˆä½¿ç”¨æŒä¹…åŒ–æ’ä»¶ï¼‰
    /// # Example (using persistence plugin)
    ///
    /// ```rust,ignore
    /// use mofa_sdk::persistence::{PersistencePlugin, PostgresStore};
    ///
    /// let store = PostgresStore::connect("postgres://localhost/mofa").await?;
    /// let user_id = Uuid::now_v7();
    /// let tenant_id = Uuid::now_v7();
    /// let agent_id = Uuid::now_v7();
    /// let session_id = Uuid::now_v7();
    ///
    /// let plugin = PersistencePlugin::new(
    ///     "persistence-plugin",
    ///     Arc::new(store),
    ///     user_id,
    ///     tenant_id,
    ///     agent_id,
    ///     session_id,
    /// );
    ///
    /// let agent = LLMAgentBuilder::from_env()?
    ///     .with_system_prompt("You are helpful.")
    ///     .with_persistence_plugin(plugin)
    ///     .build_async()
    ///     .await;
    /// ```
    pub async fn build_async(mut self) -> LLMAgent {
        let provider = self
            .provider
            .expect("LLM provider must be set before building");

        // Clone tenant_id for potential fallback use before moving into config
        // Clone tenant_id for potential fallback use before moving into config
        let tenant_id_for_persistence = self.tenant_id.clone();

        let config = LLMAgentConfig {
            agent_id: self.agent_id.clone(),
            name: self.name.unwrap_or_else(|| self.agent_id.clone()),
            system_prompt: self.system_prompt,
            temperature: self.temperature,
            max_tokens: self.max_tokens,
            custom_config: self.custom_config,
            user_id: self.user_id,
            tenant_id: self.tenant_id,
            context_window_size: self.context_window_size,
        };

        // Fallback: If stores are set but persistence_tenant_id is None, use tenant_id
        // Fallback: If stores are set but persistence_tenant_id is None, use tenant_id
        let persistence_tenant_id = if self.session_store.is_some()
            && self.persistence_tenant_id.is_none()
            && let Some(ref tenant_id) = tenant_id_for_persistence
        {
            uuid::Uuid::parse_str(tenant_id).ok()
        } else {
            self.persistence_tenant_id
        };

        // ä½¿ç”¨å¼‚æ­¥æ–¹æ³•ï¼Œæ”¯æŒä»æ•°æ®åº“åŠ è½½
        // Use asynchronous method, supporting loading from database
        let mut agent = LLMAgent::with_initial_session_async(
            config,
            provider,
            self.session_id,
            self.message_store,
            self.session_store,
            self.persistence_user_id,
            persistence_tenant_id,
            self.persistence_agent_id,
        )
        .await;

        // è®¾ç½®Promptæ¨¡æ¿æ’ä»¶
        // Set Prompt template plugin
        agent.prompt_plugin = self.prompt_plugin;

        if self.tools.is_empty()
            && let Some(executor) = self.tool_executor.as_ref()
            && let Ok(tools) = executor.available_tools().await
        {
            self.tools = tools;
        }

        if let Some(executor) = self.tool_executor {
            agent.set_tools(self.tools, executor);
        }

        // å¤„ç†æ’ä»¶åˆ—è¡¨ï¼š
        // Process plugin list:
        // 1. ä»æŒä¹…åŒ–æ’ä»¶åŠ è½½å†å²ï¼ˆæ–°æ–¹å¼ï¼‰
        // 1. Load history from persistence plugin (new way)
        // 2. æå– TTS æ’ä»¶
        // 2. Extract TTS plugin
        let mut plugins = self.plugins;
        let mut tts_plugin = None;
        let history_loaded_from_plugin = false;

        // æŸ¥æ‰¾å¹¶æå– TTS æ’ä»¶
        // Find and extract the TTS plugin
        for i in (0..plugins.len()).rev() {
            if plugins[i].as_any().is::<mofa_plugins::tts::TTSPlugin>() {
                // ä½¿ç”¨ Any::downcast_ref æ£€æŸ¥ç±»å‹
                // Check type using Any::downcast_ref
                // ç”±äºæˆ‘ä»¬éœ€è¦è·å–æ‰€æœ‰æƒï¼Œè¿™é‡Œä½¿ç”¨ is æ£€æŸ¥åç§»é™¤
                // Since ownership is needed, remove after checking with 'is'
                let plugin = plugins.remove(i);
                // å°è¯• downcast
                // Attempt downcast
                if let Ok(tts) = plugin.into_any().downcast::<mofa_plugins::tts::TTSPlugin>() {
                    tts_plugin = Some(Arc::new(Mutex::new(*tts)));
                }
            }
        }

        // ä»æŒä¹…åŒ–æ’ä»¶åŠ è½½å†å²ï¼ˆæ–°æ–¹å¼ï¼‰
        // Load history from persistence plugin (new way)
        if !history_loaded_from_plugin {
            for plugin in &plugins {
                // é€šè¿‡ metadata è¯†åˆ«æŒä¹…åŒ–æ’ä»¶
                // Identify persistence plugin via metadata
                if plugin.metadata().plugin_type == PluginType::Storage
                    && plugin
                        .metadata()
                        .capabilities
                        .contains(&"message_persistence".to_string())
                {
                    // è¿™é‡Œæˆ‘ä»¬æ— æ³•ç›´æ¥è°ƒç”¨æ³›å‹ PersistencePlugin çš„ load_history
                    // We cannot directly call the generic PersistencePlugin's load_history
                    // å› ä¸º trait object æ— æ³•è®¿é—®æ³›å‹æ–¹æ³•
                    // because trait objects cannot access generic methods
                    // å†å²åŠ è½½å°†ç”± LLMAgent åœ¨é¦–æ¬¡è¿è¡Œæ—¶é€šè¿‡ store å®Œæˆ
                    // History loading will be handled by LLMAgent via store on first run
                    tracing::info!("ğŸ“¦ æ£€æµ‹åˆ°æŒä¹…åŒ–æ’ä»¶ï¼Œå°†åœ¨ agent åˆå§‹åŒ–ååŠ è½½å†å²");
                    tracing::info!(
                        "ğŸ“¦ Persistence plugin detected; history will load after agent init"
                    );
                    break;
                }
            }
        }

        // æ·»åŠ å‰©ä½™æ’ä»¶
        // Add remaining plugins
        agent.add_plugins(plugins);

        // è®¾ç½® TTS æ’ä»¶
        // Set TTS plugin
        agent.tts_plugin = tts_plugin;

        // è®¾ç½®äº‹ä»¶å¤„ç†å™¨
        // Set event handler
        if let Some(handler) = self.event_handler {
            agent.set_event_handler(handler);
        }

        agent
    }
}

// ============================================================================
// ä»é…ç½®æ–‡ä»¶åˆ›å»º
// Create from configuration file
// ============================================================================

impl LLMAgentBuilder {
    /// ä» agent.yml é…ç½®æ–‡ä»¶åˆ›å»º Builder
    /// Create Builder from agent.yml configuration file
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// use mofa_sdk::llm::LLMAgentBuilder;
    ///
    /// let agent = LLMAgentBuilder::from_config_file("agent.yml")?
    ///     .build();
    /// ```
    pub fn from_config_file(path: impl AsRef<std::path::Path>) -> LLMResult<Self> {
        let config = crate::config::AgentYamlConfig::from_file(path)
            .map_err(|e| LLMError::ConfigError(e.to_string()))?;
        Self::from_yaml_config(config)
    }

    /// ä» YAML é…ç½®åˆ›å»º Builder
    /// Create Builder from YAML configuration
    pub fn from_yaml_config(config: crate::config::AgentYamlConfig) -> LLMResult<Self> {
        let mut builder = Self::new()
            .with_id(&config.agent.id)
            .with_name(&config.agent.name);
        // é…ç½® LLM provider
        // Configure LLM provider
        if let Some(llm_config) = config.llm {
            let provider = create_provider_from_config(&llm_config)?;
            builder = builder.with_provider(Arc::new(provider));

            if let Some(temp) = llm_config.temperature {
                builder = builder.with_temperature(temp);
            }
            if let Some(tokens) = llm_config.max_tokens {
                builder = builder.with_max_tokens(tokens);
            }
            if let Some(prompt) = llm_config.system_prompt {
                builder = builder.with_system_prompt(prompt);
            }
        }

        Ok(builder)
    }

    // ========================================================================
    // æ•°æ®åº“åŠ è½½æ–¹æ³•
    // Database loading methods
    // ========================================================================

    /// ä»æ•°æ®åº“åŠ è½½ agent é…ç½®ï¼ˆå…¨å±€æŸ¥æ‰¾ï¼‰
    /// Load agent configuration from the database (global lookup).
    ///
    /// æ ¹æ® agent_code ä»æ•°æ®åº“åŠ è½½ agent é…ç½®åŠå…¶å…³è”çš„ providerã€‚
    /// Loads agent configuration and its associated provider from the database based on agent_code.
    ///
    /// # å‚æ•°
    /// # Parameters
    /// - `store`: å®ç°äº† AgentStore çš„æŒä¹…åŒ–å­˜å‚¨
    /// - `store`: Persistent storage implementing AgentStore
    /// - `agent_code`: Agent ä»£ç ï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰
    /// - `agent_code`: Agent code (unique identifier)
    ///
    /// # é”™è¯¯
    /// # Errors
    /// - å¦‚æœ agent ä¸å­˜åœ¨
    /// - If the agent does not exist
    /// - å¦‚æœ agent è¢«ç¦ç”¨ (agent_status = false)
    /// - If the agent is disabled (agent_status = false)
    /// - å¦‚æœ provider è¢«ç¦ç”¨ (enabled = false)
    /// - If the provider is disabled (enabled = false)
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// use mofa_sdk::{llm::LLMAgentBuilder, persistence::PostgresStore};
    ///
    /// let store = PostgresStore::from_env().await?;
    /// let agent = LLMAgentBuilder::from_database(&store, "my-agent").await?.build();
    /// ```
    #[cfg(feature = "persistence-postgres")]
    pub async fn from_database<S>(store: &S, agent_code: &str) -> LLMResult<Self>
    where
        S: crate::persistence::AgentStore + Send + Sync,
    {
        let config = store
            .get_agent_by_code_with_provider(agent_code)
            .await
            .map_err(|e| LLMError::Other(format!("Failed to load agent from database: {}", e)))?
            .ok_or_else(|| {
                LLMError::Other(format!(
                    "Agent with code '{}' not found in database",
                    agent_code
                ))
            })?;

        Self::from_agent_config(&config)
    }

    /// ä»æ•°æ®åº“åŠ è½½ agent é…ç½®ï¼ˆç§Ÿæˆ·éš”ç¦»ï¼‰
    /// Load agent configuration from the database (tenant isolated).
    ///
    /// æ ¹æ® tenant_id å’Œ agent_code ä»æ•°æ®åº“åŠ è½½ agent é…ç½®åŠå…¶å…³è”çš„ providerã€‚
    /// Loads agent configuration and associated provider from the database using tenant_id and agent_code.
    ///
    /// # å‚æ•°
    /// # Parameters
    /// - `store`: å®ç°äº† AgentStore çš„æŒä¹…åŒ–å­˜å‚¨
    /// - `store`: Persistent storage implementing AgentStore
    /// - `tenant_id`: ç§Ÿæˆ· ID
    /// - `tenant_id`: Tenant ID
    /// - `agent_code`: Agent ä»£ç 
    /// - `agent_code`: Agent code
    ///
    /// # é”™è¯¯
    /// # Errors
    /// - å¦‚æœ agent ä¸å­˜åœ¨
    /// - If the agent does not exist
    /// - å¦‚æœ agent è¢«ç¦ç”¨ (agent_status = false)
    /// - If the agent is disabled (agent_status = false)
    /// - å¦‚æœ provider è¢«ç¦ç”¨ (enabled = false)
    /// - If the provider is disabled (enabled = false)
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// use mofa_sdk::{llm::LLMAgentBuilder, persistence::PostgresStore};
    /// use uuid::Uuid;
    ///
    /// let store = PostgresStore::from_env().await?;
    /// let tenant_id = Uuid::parse_str("xxx-xxx-xxx")?;
    /// let agent = LLMAgentBuilder::from_database_with_tenant(&store, tenant_id, "my-agent").await?.build();
    /// ```
    #[cfg(feature = "persistence-postgres")]
    pub async fn from_database_with_tenant<S>(
        store: &S,
        tenant_id: uuid::Uuid,
        agent_code: &str,
    ) -> LLMResult<Self>
    where
        S: crate::persistence::AgentStore + Send + Sync,
    {
        let config = store
            .get_agent_by_code_and_tenant_with_provider(tenant_id, agent_code)
            .await
            .map_err(|e| LLMError::Other(format!("Failed to load agent from database: {}", e)))?
            .ok_or_else(|| {
                LLMError::Other(format!(
                    "Agent with code '{}' not found for tenant {}",
                    agent_code, tenant_id
                ))
            })?;

        Self::from_agent_config(&config)
    }

    /// ä½¿ç”¨æ•°æ®åº“ agent é…ç½®ï¼Œä½†å…è®¸è¿›ä¸€æ­¥å®šåˆ¶
    /// Use database agent config while allowing further customization.
    ///
    /// åŠ è½½æ•°æ®åº“é…ç½®åï¼Œå¯ä»¥ç»§ç»­ä½¿ç”¨ builder æ–¹æ³•è¿›è¡Œå®šåˆ¶ã€‚
    /// After loading DB config, you can continue customizing using builder methods.
    ///
    /// # ç¤ºä¾‹
    /// # Example
    ///
    /// ```rust,ignore
    /// let agent = LLMAgentBuilder::with_database_agent(&store, "my-agent")
    ///     .await?
    ///     .with_temperature(0.8)  // è¦†ç›–æ•°æ®åº“ä¸­çš„æ¸©åº¦è®¾ç½®
    ///     .with_system_prompt("Custom prompt")  // è¦†ç›–ç³»ç»Ÿæç¤ºè¯
    ///     .build();
    /// ```
    #[cfg(feature = "persistence-postgres")]
    pub async fn with_database_agent<S>(store: &S, agent_code: &str) -> LLMResult<Self>
    where
        S: crate::persistence::AgentStore + Send + Sync,
    {
        Self::from_database(store, agent_code).await
    }

    /// ä» AgentConfig åˆ›å»º Builderï¼ˆå†…éƒ¨è¾…åŠ©æ–¹æ³•ï¼‰
    /// Create Builder from AgentConfig (internal helper method).
    #[cfg(feature = "persistence-postgres")]
    pub fn from_agent_config(config: &crate::persistence::AgentConfig) -> LLMResult<Self> {
        use super::openai::{OpenAIConfig, OpenAIProvider};

        let agent = &config.agent;
        let provider = &config.provider;

        // æ£€æŸ¥ agent æ˜¯å¦å¯ç”¨
        // Check if the agent is enabled.
        if !agent.agent_status {
            return Err(LLMError::Other(format!(
                "Agent '{}' is disabled (agent_status = false)",
                agent.agent_code
            )));
        }

        // æ£€æŸ¥ provider æ˜¯å¦å¯ç”¨
        // Check if the provider is enabled.
        if !provider.enabled {
            return Err(LLMError::Other(format!(
                "Provider '{}' is disabled (enabled = false)",
                provider.provider_name
            )));
        }

        // æ ¹æ® provider_type åˆ›å»º LLM Provider
        // Create LLM Provider based on provider_type.
        let llm_provider: Arc<dyn super::LLMProvider> = match provider.provider_type.as_str() {
            "openai" | "azure" | "compatible" | "local" => {
                let mut openai_config = OpenAIConfig::new(provider.api_key.clone());
                openai_config = openai_config.with_base_url(&provider.api_base);
                openai_config = openai_config.with_model(&agent.model_name);

                if let Some(temp) = agent.temperature {
                    openai_config = openai_config.with_temperature(temp);
                }

                if let Some(max_tokens) = agent.max_completion_tokens {
                    openai_config = openai_config.with_max_tokens(max_tokens as u32);
                }

                Arc::new(OpenAIProvider::with_config(openai_config))
            }
            "anthropic" => {
                let mut cfg = AnthropicConfig::new(provider.api_key.clone());
                cfg = cfg.with_base_url(&provider.api_base);
                cfg = cfg.with_model(&agent.model_name);

                if let Some(temp) = agent.temperature {
                    cfg = cfg.with_temperature(temp);
                }
                if let Some(tokens) = agent.max_completion_tokens {
                    cfg = cfg.with_max_tokens(tokens as u32);
                }

                Arc::new(AnthropicProvider::with_config(cfg))
            }
            "gemini" => {
                let mut cfg = GeminiConfig::new(provider.api_key.clone());
                cfg = cfg.with_base_url(&provider.api_base);
                cfg = cfg.with_model(&agent.model_name);

                if let Some(temp) = agent.temperature {
                    cfg = cfg.with_temperature(temp);
                }
                if let Some(tokens) = agent.max_completion_tokens {
                    cfg = cfg.with_max_tokens(tokens as u32);
                }

                Arc::new(GeminiProvider::with_config(cfg))
            }
            "ollama" => {
                let mut ollama_config = OllamaConfig::new();
                ollama_config = ollama_config.with_base_url(&provider.api_base);
                ollama_config = ollama_config.with_model(&agent.model_name);

                if let Some(temp) = agent.temperature {
                    ollama_config = ollama_config.with_temperature(temp);
                }

                if let Some(max_tokens) = agent.max_completion_tokens {
                    ollama_config = ollama_config.with_max_tokens(max_tokens as u32);
                }

                Arc::new(OllamaProvider::with_config(ollama_config))
            }
            other => {
                return Err(LLMError::Other(format!(
                    "Unsupported provider type: {}",
                    other
                )));
            }
        };

        // åˆ›å»ºåŸºç¡€ builder
        // Create base builder.
        let mut builder = Self::new()
            .with_id(agent.id)
            .with_name(agent.agent_name.clone())
            .with_provider(llm_provider)
            .with_system_prompt(agent.system_prompt.clone())
            .with_tenant(agent.tenant_id.to_string());

        // è®¾ç½®å¯é€‰å‚æ•°
        // Set optional parameters.
        if let Some(temp) = agent.temperature {
            builder = builder.with_temperature(temp);
        }
        if let Some(tokens) = agent.max_completion_tokens {
            builder = builder.with_max_tokens(tokens as u32);
        }
        if let Some(limit) = agent.context_limit {
            builder = builder.with_sliding_window(limit as usize);
        }

        // å¤„ç† custom_params (JSONB) - å°†æ¯ä¸ª key-value æ·»åŠ åˆ° custom_config
        // Process custom_params (JSONB) - Add each key-value to custom_config.
        if let Some(ref params) = agent.custom_params
            && let Some(obj) = params.as_object()
        {
            for (key, value) in obj.iter() {
                let value_str: String = match value {
                    serde_json::Value::String(s) => s.clone(),
                    serde_json::Value::Bool(b) => b.to_string(),
                    serde_json::Value::Number(n) => n.to_string(),
                    _ => value.to_string(),
                };
                builder = builder.with_config(key.as_str(), value_str);
            }
        }

        // å¤„ç† response_format
        // Process response_format.
        if let Some(ref format) = agent.response_format {
            builder = builder.with_config("response_format", format);
        }

        // å¤„ç† stream
        // Process stream.
        if let Some(stream) = agent.stream {
            builder = builder.with_config("stream", if stream { "true" } else { "false" });
        }

        Ok(builder)
    }
}

/// ä»é…ç½®åˆ›å»º LLM Provider
/// Create LLM Provider from configuration.
fn create_provider_from_config(
    config: &crate::config::LLMYamlConfig,
) -> LLMResult<super::openai::OpenAIProvider> {
    use super::openai::{OpenAIConfig, OpenAIProvider};

    match config.provider.as_str() {
        "openai" => {
            let api_key = config
                .api_key
                .clone()
                .or_else(|| std::env::var("OPENAI_API_KEY").ok())
                .ok_or_else(|| LLMError::ConfigError("OpenAI API key not set".to_string()))?;

            let mut openai_config = OpenAIConfig::new(api_key);

            if let Some(ref model) = config.model {
                openai_config = openai_config.with_model(model);
            }
            if let Some(ref base_url) = config.base_url {
                openai_config = openai_config.with_base_url(base_url);
            }
            if let Some(temp) = config.temperature {
                openai_config = openai_config.with_temperature(temp);
            }
            if let Some(tokens) = config.max_tokens {
                openai_config = openai_config.with_max_tokens(tokens);
            }

            Ok(OpenAIProvider::with_config(openai_config))
        }
        "azure" => {
            let endpoint = config.base_url.clone().ok_or_else(|| {
                LLMError::ConfigError("Azure endpoint (base_url) not set".to_string())
            })?;
            let api_key = config
                .api_key
                .clone()
                .or_else(|| std::env::var("AZURE_OPENAI_API_KEY").ok())
                .ok_or_else(|| LLMError::ConfigError("Azure API key not set".to_string()))?;
            let deployment = config
                .deployment
                .clone()
                .or_else(|| config.model.clone())
                .ok_or_else(|| {
                    LLMError::ConfigError("Azure deployment name not set".to_string())
                })?;

            Ok(OpenAIProvider::azure(endpoint, api_key, deployment))
        }
        "compatible" | "local" => {
            let base_url = config.base_url.clone().ok_or_else(|| {
                LLMError::ConfigError("base_url not set for compatible provider".to_string())
            })?;
            let model = config
                .model
                .clone()
                .unwrap_or_else(|| "default".to_string());

            Ok(OpenAIProvider::local(base_url, model))
        }
        other => Err(LLMError::ConfigError(format!(
            "Unknown provider: {}",
            other
        ))),
    }
}

// ============================================================================
// MoFAAgent å®ç° - æ–°çš„ç»Ÿä¸€å¾®å†…æ ¸æ¶æ„
// MoFAAgent Implementation - New unified microkernel architecture.
// ============================================================================

#[async_trait::async_trait]
impl mofa_kernel::agent::MoFAAgent for LLMAgent {
    fn id(&self) -> &str {
        &self.metadata.id
    }

    fn name(&self) -> &str {
        &self.metadata.name
    }

    fn capabilities(&self) -> &mofa_kernel::agent::AgentCapabilities {
        // å°† metadata ä¸­çš„ capabilities è½¬æ¢ä¸º AgentCapabilities
        // Convert capabilities in metadata to AgentCapabilities.
        // è¿™é‡Œéœ€è¦ä½¿ç”¨ä¸€ä¸ªé™æ€çš„ AgentCapabilities å®ä¾‹
        // A static AgentCapabilities instance is required here.
        // æˆ–è€…åœ¨ LLMAgent ä¸­å­˜å‚¨ä¸€ä¸ª AgentCapabilities å­—æ®µ
        // Or store an AgentCapabilities field within LLMAgent.
        // ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªåŸºäºå½“å‰ metadata çš„å®ç°
        // For simplicity, we create an implementation based on current metadata.
        use mofa_kernel::agent::AgentCapabilities;

        // æ³¨æ„ï¼šè¿™é‡Œè¿”å›çš„æ˜¯ä¸€ä¸ªä¸´æ—¶å¼•ç”¨ï¼Œå®é™…ä½¿ç”¨ä¸­å¯èƒ½éœ€è¦è°ƒæ•´ LLMAgent çš„ç»“æ„
        // Note: This returns a temporary reference; LLMAgent structure might need adjustment.
        // æ¥å­˜å‚¨ä¸€ä¸ª AgentCapabilities å®ä¾‹
        // To store an AgentCapabilities instance.
        // è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ª hack æ¥è¿”å›ä¸€ä¸ªé™æ€å®ä¾‹
        // Here we use a hack to return a static instance.
        static CAPABILITIES: std::sync::OnceLock<AgentCapabilities> = std::sync::OnceLock::new();

        CAPABILITIES.get_or_init(|| {
            AgentCapabilities::builder()
                .tag("llm")
                .tag("chat")
                .tag("text-generation")
                .input_type(mofa_kernel::agent::InputType::Text)
                .output_type(mofa_kernel::agent::OutputType::Text)
                .supports_streaming(true)
                .supports_tools(true)
                .build()
        })
    }

    async fn initialize(
        &mut self,
        ctx: &mofa_kernel::agent::AgentContext,
    ) -> mofa_kernel::agent::AgentResult<()> {
        // åˆå§‹åŒ–æ‰€æœ‰æ’ä»¶ï¼ˆload -> initï¼‰
        // Initialize all plugins (load -> init).
        let mut plugin_config = mofa_kernel::plugin::PluginConfig::new();
        for (k, v) in &self.config.custom_config {
            plugin_config.set(k, v);
        }
        if let Some(user_id) = &self.config.user_id {
            plugin_config.set("user_id", user_id);
        }
        if let Some(tenant_id) = &self.config.tenant_id {
            plugin_config.set("tenant_id", tenant_id);
        }
        let session_id = self.active_session_id.read().await.clone();
        plugin_config.set("session_id", session_id);

        let plugin_ctx =
            mofa_kernel::plugin::PluginContext::new(self.id()).with_config(plugin_config);

        for plugin in &mut self.plugins {
            plugin
                .load(&plugin_ctx)
                .await
                .map_err(|e| mofa_kernel::agent::AgentError::InitializationFailed(e.to_string()))?;
            plugin
                .init_plugin()
                .await
                .map_err(|e| mofa_kernel::agent::AgentError::InitializationFailed(e.to_string()))?;
        }
        self.state = mofa_kernel::agent::AgentState::Ready;

        // å°†ä¸Šä¸‹æ–‡ä¿¡æ¯ä¿å­˜åˆ° metadataï¼ˆå¦‚æœéœ€è¦ï¼‰
        // Save context information to metadata (if needed).
        let _ = ctx;

        Ok(())
    }

    async fn execute(
        &mut self,
        input: mofa_kernel::agent::AgentInput,
        _ctx: &mofa_kernel::agent::AgentContext,
    ) -> mofa_kernel::agent::AgentResult<mofa_kernel::agent::AgentOutput> {
        use mofa_kernel::agent::{AgentError, AgentInput, AgentOutput};

        // å°† AgentInput è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        // Convert AgentInput to string.
        let message = match input {
            AgentInput::Text(text) => text,
            AgentInput::Json(json) => json.to_string(),
            _ => {
                return Err(AgentError::ValidationFailed(
                    "Unsupported input type for LLMAgent".to_string(),
                ));
            }
        };

        // æ‰§è¡Œ chat
        // Execute chat.
        let response = self
            .chat(&message)
            .await
            .map_err(|e| AgentError::ExecutionFailed(format!("LLM chat failed: {}", e)))?;

        // å°†å“åº”è½¬æ¢ä¸º AgentOutput
        // Convert response to AgentOutput.
        Ok(AgentOutput::text(response))
    }

    async fn shutdown(&mut self) -> mofa_kernel::agent::AgentResult<()> {
        // é”€æ¯æ‰€æœ‰æ’ä»¶
        // Destroy all plugins.
        for plugin in &mut self.plugins {
            plugin
                .unload()
                .await
                .map_err(|e| mofa_kernel::agent::AgentError::ShutdownFailed(e.to_string()))?;
        }
        self.state = mofa_kernel::agent::AgentState::Shutdown;
        Ok(())
    }

    fn state(&self) -> mofa_kernel::agent::AgentState {
        self.state.clone()
    }
}

// ============================================================================
// ä¾¿æ·å‡½æ•°
// Convenience Functions.
// ============================================================================

/// å¿«é€Ÿåˆ›å»ºç®€å•çš„ LLM Agent
/// Quickly create a simple LLM Agent.
///
/// # ç¤ºä¾‹
/// # Example
///
/// ```rust,ignore
/// use mofa_sdk::llm::{simple_llm_agent, openai_from_env};
/// use std::sync::Arc;
///
/// let agent = simple_llm_agent(
///     "my-agent",
///     Arc::new(openai_from_env()),
///     "You are a helpful assistant."
/// );
/// ```
pub fn simple_llm_agent(
    agent_id: impl Into<String>,
    provider: Arc<dyn LLMProvider>,
    system_prompt: impl Into<String>,
) -> LLMAgent {
    LLMAgentBuilder::new()
        .with_id(agent_id)
        .with_provider(provider)
        .with_system_prompt(system_prompt)
        .build()
}

/// ä»é…ç½®æ–‡ä»¶åˆ›å»º LLM Agent
/// Create LLM Agent from a configuration file.
///
/// # ç¤ºä¾‹
/// # Example
///
/// ```rust,ignore
/// use mofa_sdk::llm::agent_from_config;
///
/// let agent = agent_from_config("agent.yml")?;
/// ```
pub fn agent_from_config(path: impl AsRef<std::path::Path>) -> LLMResult<LLMAgent> {
    LLMAgentBuilder::from_config_file(path)?.try_build()
}
