//! Content moderation and prompt guard traits
//!
//! Kernel-level contracts for moderating content against security policies
//! and detecting prompt injection attacks.

use super::types::{ContentPolicy, ModerationVerdict, SecurityResult};
use async_trait::async_trait;

// =============================================================================
// Content Moderation
// =============================================================================

/// Moderates content against a configurable security policy.
///
/// Implementations evaluate text content and return a verdict indicating
/// whether the content should be allowed, flagged, or blocked.
///
/// # Example
///
/// ```rust,ignore
/// let moderator = KeywordModerator::new(blocked_words);
/// let policy = ContentPolicy::default();
/// let verdict = moderator.moderate("some user input", &policy).await?;
/// match verdict {
///     ModerationVerdict::Allow => { /* proceed */ }
///     ModerationVerdict::Block { reason, .. } => { /* reject */ }
///     ModerationVerdict::Flag { reason, .. } => { /* log and proceed */ }
/// }
/// ```
#[async_trait]
pub trait ContentModerator: Send + Sync {
    /// Evaluate content against the given policy.
    async fn moderate(
        &self,
        content: &str,
        policy: &ContentPolicy,
    ) -> SecurityResult<ModerationVerdict>;
}

// =============================================================================
// Prompt Injection Guard
// =============================================================================

/// Detects prompt injection attempts in user-supplied prompts.
///
/// This trait extends the Rhai script injection prevention from PR #318
/// to cover broader prompt injection patterns including:
/// - System prompt extraction attempts
/// - Role override / hijacking
/// - Instruction ignoring patterns
/// - Delimiter-based injection
///
/// # Example
///
/// ```rust,ignore
/// let guard = RegexPromptGuard::default();
/// let verdict = guard.check_prompt("Ignore all previous instructions").await?;
/// assert!(verdict.is_blocked());
/// ```
#[async_trait]
pub trait PromptGuard: Send + Sync {
    /// Check a prompt for injection attempts.
    async fn check_prompt(&self, prompt: &str) -> SecurityResult<ModerationVerdict>;
}

// =============================================================================
// Tests
// =============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    // Verify trait object safety â€” these must compile
    fn _assert_moderator_object_safe(_: &dyn ContentModerator) {}
    fn _assert_guard_object_safe(_: &dyn PromptGuard) {}

    #[test]
    fn trait_object_safety() {
        fn _takes_moderator(_: Box<dyn ContentModerator>) {}
        fn _takes_guard(_: Box<dyn PromptGuard>) {}
    }
}
